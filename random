

# 2. Convert TRUE/FALSE binary flags to 1/0
binary_columns = [
    "browser_access_flag", "jpm_lockbox_image_file_flag", "non_jpm_lockbox_image_file_flag",
    "self_scanning_lockbox_image_file_flag", "pdf_image_file_to_835_flag", "patient_payment_flag",
    "paper_eob_conversion_to_835_flag", "835_outbound_transmission_commercial_era_uploading_flag",
    "epic_cash_management_file_flag", "835_outbound_transmission_commercial_flag",
    "835_outbound_transmission_patientpay_flag", "outbound_hcl_image_transmission_flag",
    "reconciliation_manager_flag", "reconciliation_manager_enterprise_flag", "corr_index_flag",
    "835_packet_split_flag", "fispan_flag"
]

for col in binary_columns:
    df[col] = df[col].astype(str).str.upper().map({'TRUE': 1, 'FALSE': 0})
    df[col] = df[col].fillna(0)

# 3. Drop rows with nulls in important columns
required_cols = ["pli_active_cycle_time", "pli_type"]
df = df.dropna(subset=required_cols)
print(f"âœ… After dropping rows with nulls: {df.shape}")

# 4. Feature setup
multi_categorical_features = ["pli_type"]
categorical_features = binary_columns + multi_categorical_features
target = "pli_active_cycle_time"
X = df[categorical_features]
y = df[target]

# 5. Pipeline: OneHot + LinearRegression
preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
])

pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", LinearRegression())
])

# 6. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Train model
pipeline.fit(X_train, y_train)

# 8. Predict and evaluate
y_pred = pipeline.predict(X_test)
print("\nðŸ“Š Model Evaluation:")
print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
print(f"RÂ² Score: {r2_score(y_test, y_pred):.2f}")

# 9. Feature Importance
regressor = pipeline.named_steps["regressor"]
ohe = pipeline.named_steps["preprocessor"].named_transformers_["cat"]
feature_names = ohe.get_feature_names_out(categorical_features)

coef_df = pd.DataFrame({
    "Feature": feature_names,
    "Coefficient": regressor.coef_
}).sort_values(by="Coefficient", key=abs, ascending=False)

print("\nðŸ“Œ Top Feature Coefficients:")
print(coef_df.head(10))

# 10. Predict full dataset
df["predicted_cycle_time"] = pipeline.predict(X)

# 11. Binning for Complexity Score (1â€“5)
binning = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')
df["complexity_score"] = binning.fit_transform(df[["predicted_cycle_time"]]).astype(int) + 1

# 12. Charts
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Cycle Time")
plt.ylabel("Predicted Cycle Time")
plt.title("Actual vs Predicted")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(6, 4))
sns.countplot(x="complexity_score", data=df)
plt.title("Complexity Score Distribution")
plt.xlabel("Score (1 = Low, 5 = High)")
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x="Coefficient", y="Feature", data=coef_df.head(15), palette="viridis")
plt.title("Top 15 Feature Importances")
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

# 13. Export to Excel
df.to_excel("pli_with_complexity_scores.xlsx", index=False)
coef_df.to_excel("feature_importance_linear_model.xlsx", index=False)
print("âœ… Output saved to Excel")

