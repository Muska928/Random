import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import os

# Load data
df = pd.read_excel('Data/closed_won_final.csv')  # Ensure this path is correct
df = df.head(10)  # Limiting to only 10 rows
total_rows = len(df)

# Load model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Model loading
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    trust_remote_code=True,
    device_map="auto"
)

# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Function to save batch results to disk
def save_results(df_sample, filename='3_intermediate_results.csv'):
    if not os.path.exists(filename):
        df_sample.to_csv(filename, index=False, mode='w')
    else:
        df_sample.to_csv(filename, index=False, mode='a', header=False)
    print(f"Batch saved to {filename}.")

# Function to classify text based on Category and Explanation
def classify_texts(df_batch):
    results = []

    # Define the improved prompt template for classification
    updated_prompt_template = """
    You are a highly intelligent AI model trained to analyze and classify text based on its content, especially in the context of financial and account-related processes. Your task is to classify the text into one of the following categories based on what it describes:

    ### Categories:
    1. **Account Opening**: The text describes the process of opening a new account, either for a new or existing client.
    2. **Account Closure**: The text refers to the closing of an existing account, termination of client relationships, or steps related to discontinuing an account.
    3. **Account Configuration**: The text involves setting up, configuring, or modifying an existing account’s settings, features, or permissions, including adding or removing services.
    4. **Account Transfer**: The text discusses the transfer of funds between accounts, shifting accounts between banks, or transferring ownership of accounts.
    5. **Other Processes**: The text describes an account-related process that doesn’t fit the above categories (e.g., client access addition, connectivity setup, etc.).

    ### Instructions:
    1. Read the provided text carefully.
    2. Determine which of the five categories the text fits into. Choose the most appropriate category based on the context of the text.
    3. If the category is "Other Processes," provide a short description of the process (2-3 words).
    4. Provide a clear explanation of why this category fits the text, referencing key terms, phrases, or actions described.

    Now, classify the following text:

    Text: "{input_text}"

    ### Response Format:
    1. Category: [Account Opening / Account Closure / Account Configuration / Account Transfer / Other Processes]
    2. Process (if "Other Processes" is selected): [A short 2-3 word description]
    3. Explanation: [A brief explanation that refers to key terms in the text]
    """
    
    batch_texts = df_batch["combined_text"].tolist()
    
    # Create prompts and generate responses
    prompts = [updated_prompt_template.format(input_text=text) for text in batch_texts]
    batch_responses = generation_pipeline(prompts, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    
    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]['generated_text']
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        results.append(generated_text)
    
    df_batch['final_response_classify'] = results

# Extract the "Category" and "Explanation"
def extract_information_classify(text):
    lines = text.split("\n")
    category = "Not available"
    process = "Not available"
    explanation = "Not available"

    for line in lines:
        if line.strip().startswith("1. Category:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                category = parts[1].strip()
        elif line.strip().startswith("2. Process:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                process = parts[1].strip()
        elif line.strip().startswith("3. Explanation:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                explanation = parts[1].strip()
    
    return category, process, explanation

# Function for Topic Alignment With LDA
def topic_alignment_lda(df_batch):
    results = []

    # Define the updated prompt template to check topic alignment with text context
    updated_prompt_template = """
    You are an AI tasked with verifying if the assigned topic name matches the context of the content provided.
    Assess whether the topic assigned is relevant and appropriate for the text.
    Given the following text, identify if the assigned topic name aligns with the content:
    
    Assigned Topic Name: {topic_name}
    Text: {input_text}
    
    Provide your response in the following format:
    Topic Alignment: (Yes/No)
    Explanation: [Brief explanation of why the topic does or does not match the content]
    """
    
    batch_texts = df_batch["combined_text"].tolist()
    assigned_topics = df_batch["main_topic_name"].tolist()
    
    prompts = [updated_prompt_template.format(topic_name=topic, input_text=text) for topic, text in zip(assigned_topics, batch_texts)]
    batch_responses = generation_pipeline(prompts, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    
    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]['generated_text']
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        results.append(generated_text)
    
    df_batch['final_response_topic_alignment'] = results

# Extract topic alignment and explanation
def extract_information_alignment(text):
    lines = text.split("\n")
    topic_alignment = "Not available"
    explanation = "Not available"

    for line in lines:
        if line.strip().startswith("Topic Alignment:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                topic_alignment = parts[1].strip()
        elif line.strip().startswith("Explanation:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                explanation = parts[1].strip()
    
    return topic_alignment, explanation

# Main function to process batches without repetition
def process_batches(df, batch_size):
    # Clear the intermediate file before starting
    intermediate_file = '3_intermediate_results.csv'
    if os.path.exists(intermediate_file):
        os.remove(intermediate_file)

    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process (ensure unique rows are processed per batch)
        df_batch = df.iloc[start:end].copy()
        
        # Run classification task
        classify_texts(df_batch)
        
        # Run topic alignment task
        topic_alignment_lda(df_batch)
        
        # Save intermediate results after processing
        save_results(df_batch, filename=intermediate_file)

    # Save final combined results to new file after all batches are processed
    try:
        df_combined = pd.read_csv(intermediate_file, on_bad_lines='skip')
        df_combined.to_csv('new_Deals_Topic_Alignment_Output.csv', index=False)
        print("Final results saved to new_Deals_Topic_Alignment_Output.csv.")
    except pd.errors.ParserError as e:
        print(f"Error reading CSV: {e}")

# Run the process with batch size
process_batches(df, batch_size=5)

# After all batches are processed, load the final CSV and extract category, explanation, topic alignment, and topic explanation
try:
    df_final = pd.read_csv('new_Deals_Topic_Alignment_Output.csv', on_bad_lines='skip')
    
    if not df_final.empty:
        df_final[['category', 'process', 'explanation']] = df_final['final_response_classify'].apply(lambda x: pd.Series(extract_information_classify(x)))
        df_final[['topic_alignment', 'topic_explanation']] = df_final['final_response_topic_alignment'].apply(lambda x: pd.Series(extract_information_alignment(x)))

        df_final.to_csv('new_Deals_Topic_Alignment_Output.csv', index=False)
        print("Final results saved to CSV.")
    
    # Display the results for verification
    print(df_final[['category', 'process', 'explanation', 'topic_alignment', 'topic_explanation']].head())

except pd.errors.ParserError as e:
    print(f"Error reading final output CSV: {e}")
