# Tokenize the cleaned text
tokens = non_rst_cleaned['cleaned_text'].apply(lambda x: x.split())

# Perform N-gram Analysis
unigram_freq = Counter([token for tokens_list in tokens for token in tokens_list])
bigram_freq = get_ngram_freqs([token for tokens_list in tokens for token in tokens_list], 2)
trigram_freq = get_ngram_freqs([token for tokens_list in tokens for token in tokens_list], 3)

display_ngrams(unigram_freq, 'Unigrams')
display_ngrams(bigram_freq, 'Bigrams')
display_ngrams(trigram_freq, 'Trigrams')
