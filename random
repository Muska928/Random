def classify_texts(df_batch):
    assigned_categories = []
    sub_categories = []
    specific_processes = []
    account_opening_flags = []

    prompt_template = """
    You are an AI tasked with reading a text related to financial and business processes. 
    First, determine if this case is related to **Account Opening**.

    - If it mentions actual account creation (e.g., "Account Opening", "New Account", "Account Setup"), 
    assign it as **Account Opening**.

    - If it mentions **interest** or **inquiry** without actual opening (e.g., "Client interested", "Inquiry about account"), 
    assign the category as **Not Account Opening**.

    - If it involves modifications to an **existing account**, assign it as **Already Existing Account**.

    After categorizing the text into one of these high-level categories, you must also provide a sub-category and describe the specific process in 2-3 words that is happening in the text.

    If none of the categories fit, assign **Others** for both High-Level and Sub-Category.

    Text: "{input_text}"

    ### Response Format:
    1. High-Level Category: [Account Opening / Already Existing Account / Not Account Opening / Others]
    2. Sub-Category: [Assigned Sub-Category with Location (if applicable) or "Others"]
    3. Specific Process: [2-3 word process description]
    """

    for idx, row in df_batch.iterrows():
        input_text = row["combined_text"]
        # **Chunk the input text**
        text_chunks = chunk_text(input_text)  # Use input_text, not the prompt
        
        # Variables to collect results from chunks
        combined_category = []
        combined_sub_category = []
        combined_process = []

        for chunk in text_chunks:
            # Convert chunk back to text
            chunk_text_decoded = tokenizer.decode(chunk)

            # Create prompt for each chunk
            prompt = prompt_template.format(input_text=chunk_text_decoded)

            # Tokenization and model inference for each chunk
            input_tokens = tokenizer(prompt, return_tensors="pt", truncation=True, padding=True, max_length=512).to(model.device)
            output = model.generate(input_tokens['input_ids'], max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)

            # Decode and extract results
            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

            # Debugging: Check what the model has generated
            print(f"Generated text for chunk in row {idx}: {generated_text}")

            # Extract classification results from each chunk
            category, sub_category, process = extract_classification(generated_text)

            # Collect results from each chunk
            combined_category.append(category)
            combined_sub_category.append(sub_category)
            combined_process.append(process)

        # **Aggregate chunk results**
        # For simplicity, you can take the most frequent category and process across chunks.
        final_category = max(set(combined_category), key=combined_category.count)
        final_sub_category = max(set(combined_sub_category), key=combined_sub_category.count)
        final_process = " ".join(combined_process)  # Combine processes from chunks

        # Save the classification results for each row
        assigned_categories.append(final_category)
        sub_categories.append(final_sub_category)
        specific_processes.append(final_process)

        # Set flag for account opening
        if final_category == "Account Opening":
            account_opening_flags.append("Yes")
        else:
            account_opening_flags.append("No")

    df_batch['assigned_category'] = assigned_categories
    df_batch['sub_category'] = sub_categories
    df_batch['specific_process'] = specific_processes
    df_batch['is_related_to_account_opening'] = account_opening_flags

    return df_batch

