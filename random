
# Load Data
df = pd.read_csv('Data/closed_won_final.csv')
df = df.head(1)  # Limiting to 1000 rows for demonstration
total_rows = len(df)

# Define the prompt template
prompt_template = """
You are an AI tasked with reading a text related to financial and business processes. 
First, determine if this case is related to **Account Opening**.

If it mentions actual account creation (e.g., "Account Opening", "New Account", "Account Setup"), 
assign it as **Account Opening**.

If it involves modifications to an **existing account**, assign it as **Already Existing Account**.

Text: "{input_text}"

### Response Format:
1. Category: [Account Opening / Already Existing Account / Not Account Opening / Others]
2. Specific Process: [Assigned Process or 'Others']
"""

# Function to extract the category and process
def extract_category_process(text):
    lines = text.split("\n")
    category = "Not available"
    process = "Not available"

    for line in lines:
        line = line.strip()
        if line.startswith("1. Category:"):
            category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("2. Specific Process:"):
            process = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
    
    return category, process

# Process data in batches
def process_batches(df, batch_size=100):
    all_results = pd.DataFrame()

    start_time = time.time()

    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        df_batch = df.iloc[start:end].copy()

        # Classify texts in the batch
        categories = []
        processes = []

        for idx, row in df_batch.iterrows():
            input_text = row["combined_text"]
            prompt = prompt_template.format(input_text=input_text)

            # Debugging: print the prompt to verify it
            print(f"Processing record {idx} with prompt:\n{prompt}")

            # Tokenization and inference
            try:
                input_tokens = tokenizer(prompt, return_tensors="pt", truncation=True, padding=True, max_length=512).to(model.device)
                output = model.generate(input_tokens['input_ids'], max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)

                # Decode and extract results
                generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

                # Debugging: print the generated text for inspection
                print(f"Generated text for record {idx}:\n{generated_text}")

                # Extract category and process
                category, process = extract_category_process(generated_text)

            except Exception as e:
                # Debugging: print error if exception occurs
                print(f"Error occurred during processing record {idx}: {e}")
                category, process = "Error", "Error"

            # Append the results
            categories.append(category)
            processes.append(process)

        # Save the batch results to DataFrame
        df_batch['assigned_category'] = categories
        df_batch['specific_process'] = processes

        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Save the final combined results
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Time taken to process {len(df)} records: {elapsed_time:.2f} seconds")

    all_results.to_csv('final_classification_output.csv', index=False)
    print("Final results saved to final_classification_output.csv.")

# Run the batch process
process_batches(df, batch_size=1)

# Display the first few rows of the saved output
df_final = pd.read_csv('final_classification_output.csv')
print(df_final.head())
