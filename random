# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Dictionary to store assignments for reuse and track repetition
assignment_memory = {}

def classify_texts(df_batch):
    assigned_categories = []
    sub_categories = []
    specific_processes = []
    account_opening_flags = []
    repetition_labels = []
    confidence_scores = []

    # Define the updated prompt template for high-level and sub-category classification
    updated_prompt_template = """
    You are an AI tasked with reading a text related to financial and business processes. First, determine if this case is related to **Account Opening**.
    
    - If yes, assign the category as **Account Opening** and include any specific location mentioned (e.g., "Account Opening in Dubai" or "DDA Account Opening in US").
    - If no, assign it under **Already Existing Account** or **Not Account Opening** based on the context, and include any relevant location (e.g., "Account Maintenance in London" or "Personnel Change in London").

    After categorizing the text into one of these high-level categories, you must also provide a sub-category and describe the specific process in 2-3 words that is happening in the text.

    Text: "{input_text}"

    ### Response Format:
    1. High-Level Category: [Account Opening / Already Existing Account / Not Account Opening]
    2. Sub-Category: [Assigned Sub-Category with Location (if applicable)]
    3. Specific Process: [2-3 word process description]
    """

    batch_texts = df_batch["combined_text"].tolist()

    for text in batch_texts:
        # Check if the text has been previously classified
        if text in assignment_memory:
            assigned_category, sub_category, specific_process, confidence = assignment_memory[text]
            assigned_categories.append(assigned_category)
            sub_categories.append(sub_category)
            specific_processes.append(specific_process)
            confidence_scores.append(confidence)
            account_opening_flags.append("Yes" if "Account Opening" in assigned_category else "No")
            repetition_labels.append("Repetitive")
        else:
            # Create prompt and generate response
            prompt = updated_prompt_template.format(input_text=text)
            response = generation_pipeline(prompt, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
            
            # Extract the generated text
            generated_text = response[0]['generated_text'] if response else "No valid response"
            
            # Extract high-level category, sub-category, process, and confidence score
            high_level_category, sub_category, process, confidence = extract_classification(generated_text)
            
            # Append results
            assigned_categories.append(high_level_category)
            sub_categories.append(sub_category)
            specific_processes.append(process)
            confidence_scores.append(confidence)
            repetition_labels.append("Unique")
            
            # Store the result for future reuse
            assignment_memory[text] = (high_level_category, sub_category, process, confidence)
            
            # Set the "Account Opening" flag
            account_opening_flags.append("Yes" if "Account Opening" in high_level_category else "No")
    
    # Add the classification results, repetition label, confidence score, and flags to the DataFrame
    df_batch['assigned_category'] = assigned_categories
    df_batch['sub_category'] = sub_categories
    df_batch['specific_process'] = specific_processes
    df_batch['confidence_score'] = confidence_scores
    df_batch['is_related_to_account_opening'] = account_opening_flags
    df_batch['repetition_label'] = repetition_labels
    
    return df_batch

# Extract the high-level category, sub-category, specific process, and confidence score from the generated text
def extract_classification(text):
    # Split the text into lines
    lines = text.split("\n")
    high_level_category = "Not available"
    sub_category = "Not available"
    specific_process = "Not available"
    confidence = "Not available"

    # Loop through the lines to find the high-level category, sub-category, and confidence score
    for line in lines:
        line = line.strip()
        if line.startswith("1. High-Level Category:"):
            high_level_category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("2. Sub-Category:"):
            sub_category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("3. Specific Process:"):
            specific_process = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("4. Confidence:"):
            confidence = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
    
    return high_level_category, sub_category, specific_process, confidence

# Main function to process batches
def process_batches(df, batch_size):
    all_results = pd.DataFrame()

    # Measure the start time
    start_time = time.time()

    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()
        
        # Run classification task
        df_batch = classify_texts(df_batch)
        
        # Append the classified results to the full dataframe
        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Measure the end time
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Time taken to process {len(df)} records: {elapsed_time:.2f} seconds")

    # Save final combined results to new file after all batches are processed
    all_results.to_csv('final_classification_output_with_confidence.csv', index=False)
    print("Final results saved to final_classification_output_with_confidence.csv.")

# Run the process with batch size
process_batches(df, batch_size=10)

# Check the final DataFrame content
df_final = pd.read_csv('final_classification_output_with_confidence.csv')
print(df_final.head())


------

# Dictionary to store assignments for reuse and track repetition
assignment_memory = {}

def classify_texts(df_batch):
    assigned_categories = []
    specific_processes = []
    account_opening_flags = []
    repetition_labels = []
    confidence_scores = []

    # Define the updated prompt template for hierarchical classification and location-specific context with confidence
    updated_prompt_template = """
    You are an AI tasked with reading a text related to financial and business processes. Follow the steps below to classify the text into a high-level category first, then assign a more specific sub-category and describe the process:

    ### High-Level Categories:
    1. **Account Opening**: This includes any new account creation (e.g., New Account, DDA, Location-Specific Accounts).
    2. **Already Existing Account**: This includes any operations or modifications related to an already existing account.
    3. **Not Account Opening**: If the text is not related to any form of account opening or existing account operations.

    ### Sub-Categories:
    - For **Account Opening**:
        - **Regional Account Opening** (e.g., U.S., EMEA)
        - **Country-Specific Account Opening** (e.g., Canada, UK)
        - **Product-Specific Account Opening** (e.g., BACA, Cash Concentration)

    - For **Already Existing Account**:
        - **Account Maintenance**
        - **Account Modifications**
        - **Transfer Requests**

    - For **Not Account Opening**:
        - **Business Operations**: Business mergers, partnerships, market disruptions, etc.
        - **Client & Customer Services**: Client onboarding, customer support, etc.
        - **Transaction Processing**: Transaction reviews, transfers, payments.

    ### Response Format:
    1. High-Level Category: [Account Opening / Already Existing Account / Not Account Opening]
    2. Sub-Category: [Assigned Sub-Category]
    3. Specific Process: [2-3 word process description]
    4. Confidence: [Confidence level (0-100%)]

    Text: "{input_text}"
    """

    batch_texts = df_batch["combined_text"].tolist()

    for text in batch_texts:
        # Check if the text has been previously classified
        if text in assignment_memory:
            assigned_category, specific_process, confidence = assignment_memory[text]
            assigned_categories.append(assigned_category)
            specific_processes.append(specific_process)
            confidence_scores.append(confidence)
            account_opening_flags.append("Yes" if "Account Opening" in assigned_category else "No")
            repetition_labels.append("Repetitive")
        else:
            # Create prompt and generate response
            prompt = updated_prompt_template.format(input_text=text)
            response = generation_pipeline(prompt, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
            
            # Extract the generated text
            generated_text = response[0]['generated_text'] if response else "No valid response"
            
            # Extract the high-level category, sub-category, process, and confidence score
            high_level_category, sub_category, process, confidence = extract_hierarchical_classification(generated_text)
            
            # Combine the high-level and sub-categories for storage
            full_category = f"{high_level_category} - {sub_category}"
            assigned_categories.append(full_category)
            specific_processes.append(process)
            confidence_scores.append(confidence)
            repetition_labels.append("Unique")
            
            # Store the result for future reuse
            assignment_memory[text] = (full_category, process, confidence)
            
            # Set the "Account Opening" flag
            account_opening_flags.append("Yes" if "Account Opening" in full_category else "No")
    
    # Add the classification results, repetition label, confidence score, and flags to the DataFrame
    df_batch['assigned_category'] = assigned_categories
    df_batch['specific_process'] = specific_processes
    df_batch['confidence_score'] = confidence_scores
    df_batch['is_related_to_account_opening'] = account_opening_flags
    df_batch['repetition_label'] = repetition_labels
    
    return df_batch

# Extract the high-level category, sub-category, specific process, and confidence score from the generated text
def extract_hierarchical_classification(text):
    # Split the text into lines
    lines = text.split("\n")
    high_level_category = "Not available"
    sub_category = "Not available"
    process = "Not available"
    confidence = "Not available"

    # Loop through the lines to find the high-level category, sub-category, process, and confidence
    for line in lines:
        line = line.strip()
        if line.startswith("1. High-Level Category:"):
            high_level_category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("2. Sub-Category:"):
            sub_category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("4. Specific Process:"):
            process = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("5. Confidence:"):
            confidence = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
    
    return high_level_category, sub_category, process, confidence

# Main function to process batches
def process_batches(df, batch_size):
    all_results = pd.DataFrame()

    # Measure the start time
    start_time = time.time()

    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()
        
        # Run classification task
        df_batch = classify_texts(df_batch)
        
        # Append the classified results to the full dataframe
        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Measure the end time
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Time taken to process {len(df)} records: {elapsed_time:.2f} seconds")

    # Save final combined results to new file after all batches are processed
    all_results.to_csv('final_classification_output_with_confidence.csv', index=False)
    print("Final results saved to final_classification_output_with_confidence.csv.")

# Run the process with batch size
process_batches(df, batch_size=10)

# Check the final DataFrame content
df_final = pd.read_csv('final_classification_output_with_confidence.csv')
print(df_final.head())
                                        

                                         
