# Extract top words from each topic
def extract_top_words(model, num_words):
    top_words_per_topic = []
    for topic_id in range(model.num_topics):
        top_words = model.show_topic(topic_id, num_words)
        top_words_per_topic.append(" ".join([word for word, _ in top_words]))
    return top_words_per_topic

# Assign the main topic for each document in the corpus
def get_main_topic(corpus):
    topic_weights = optimal_model[corpus]
    main_topic = max(topic_weights, key=lambda x: x[1])  # Get the topic with the highest weight
    return main_topic[0]

# Apply the get_main_topic function to all the documents
non_rst_gt_3_tokens['main_topic'] = [get_main_topic(corp) for corp in corpus]

# Extract topic names
top_words_per_topic = extract_top_words(optimal_model, 5)

# Assign the topic name correlated with the main topic rank
non_rst_gt_3_tokens['main_topic_name'] = non_rst_gt_3_tokens['main_topic'].apply(lambda x: top_words_per_topic[x])

# Calculate the frequency of each topic
topic_frequency = non_rst_gt_3_tokens['main_topic_name'].value_counts().reset_index()
topic_frequency.columns = ['Topic Name', 'Frequency']

# Print the topic frequency summary
print("\nLDA Topic Frequency Summary:")
print(topic_frequency)

# Optionally, save to Excel
topic_frequency.to_excel('lda_topic_frequency_summary.xlsx', index=False)

# You can also plot the distribution of topics
plt.figure(figsize=(12, 6))
sns.barplot(x='Topic Name', y='Frequency', data=topic_frequency, palette='coolwarm')
plt.xticks(rotation=45, ha='right', fontsize=12)
plt.xlabel('Topic Name', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.title("LDA Topic Frequency Summary", fontsize=16, weight='bold')
plt.tight_layout()
plt.show()
