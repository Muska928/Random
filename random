import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

# Load data
df = pd.read_excel("hcl_spec_level_data (1).xlsx")
df.dropna(inplace=True)

# Identify binary and multi-categorical features
binary_categorical_features = [
    "browser_access_flag", "jpm_lockbox_image_file_flag", "non_jpm_lockbox_image_file_flag",
    "self_scanning_lockbox_image_file_flag", "pdf_image_file_to_835_flag", "patient_payment_flag",
    "paper_eob_conversion_to_835_flag", "835_outbound_transmission_commercial_era_uploading_flag",
    "epic_cash_management_file_flag", "835_outbound_transmission_commercial_flag",
    "835_outbound_transmission_patientpay_flag", "outbound_hcl_image_transmission_flag",
    "reconciliation_manager_flag", "reconciliation_manager_enterprise_flag", "corr_index_flag",
    "835_packet_split_flag", "fispan_flag"
]
multi_categorical_features = ["pli_type"]
categorical_features = binary_categorical_features + multi_categorical_features

# ðŸ”§ Feature engineering
df['has_multiple_flags_on'] = df[binary_categorical_features].sum(axis=1)
df['is_image_file_used'] = df[
    ["jpm_lockbox_image_file_flag", "non_jpm_lockbox_image_file_flag", "self_scanning_lockbox_image_file_flag", "pdf_image_file_to_835_flag"]
].max(axis=1)

# Updated features and target
categorical_features += ['has_multiple_flags_on', 'is_image_file_used']
target = 'pli_active_cycle_time'
X = df[categorical_features]
y = df[target]

# Optional log transformation if skewed
y_log = np.log1p(y)  # log(1 + y) to avoid log(0)

# Preprocessing pipeline
preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
])

pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", LinearRegression())  # Try RandomForestRegressor() optionally
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=0.2, random_state=42)

# Fit model
pipeline.fit(X_train, y_train)

# Predict
y_pred_log = pipeline.predict(X_test)
y_pred = np.expm1(y_pred_log)  # reverse log1p

# Evaluation
print("\nModel Evaluation:")
print(f"MAE: {mean_absolute_error(np.expm1(y_test), y_pred):.2f}")
print(f"RÂ² Score: {r2_score(np.expm1(y_test), y_pred):.2f}")

# Predict full cycle time for binning
df["predicted_cycle_time"] = np.expm1(pipeline.predict(X))

# ðŸ§® Binning with fewer bins to avoid warning
binning = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')  # or strategy='quantile'
df["complexity_score"] = binning.fit_transform(df[["predicted_cycle_time"]]).astype(int) + 1  # scale 1â€“3

# ðŸ“Š Plot actual vs predicted
plt.figure(figsize=(8, 5))
sns.scatterplot(x=np.expm1(y_test), y=y_pred)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Actual Cycle Time")
plt.ylabel("Predicted Cycle Time")
plt.title("Actual vs Predicted Cycle Time")
plt.grid(True)
plt.tight_layout()
plt.show()

# ðŸ“Š Complexity score distribution
plt.figure(figsize=(6, 4))
sns.countplot(x="complexity_score", data=df)
plt.title("Complexity Score Distribution")
plt.xlabel("Complexity (1 = Low, 3 = High)")
plt.tight_layout()
plt.show()

# ðŸ“Œ Feature Importance (only for Linear Regression)
regressor = pipeline.named_steps['regressor']
onehot = pipeline.named_steps['preprocessor'].named_transformers_['cat']
feature_names = onehot.get_feature_names_out(categorical_features)

coef_df = pd.DataFrame({
    "Feature": feature_names,
    "Coefficient": regressor.coef_
}).sort_values(by="Coefficient", key=abs, ascending=False)

print("\nTop Feature Coefficients:")
print(coef_df.head(10))

# Save to Excel
df.to_excel("hcl_complexity_output_v2.xlsx", index=False)
coef_df.to_excel("hcl_feature_importance_v2.xlsx", index=False)

