# Import necessary libraries
import pandas as pd
import spacy
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
from spacy.lang.en.stop_words import STOP_WORDS
import gensim
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis
from gensim.models import CoherenceModel
from datetime import datetime
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Load Spacy model and data
nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])
df_salesforce = pd.read_excel('Data/Closed_Won Reasons/Closed_Won_Product_Capability.xlsx')

# Check for missing values function (as provided in your code)
# Additional code for handling text preprocessing and processing pipeline
# ...

# Function to apply LDA after bigram and trigram creation
def apply_lda(processed_texts, num_topics=10, passes=10):
    # Create bigram and trigram models
    bigram = gensim.models.Phrases(processed_texts, min_count=10)
    trigram = gensim.models.Phrases(bigram[processed_texts], min_count=10)

    # Add bigrams and trigrams to texts
    processed_texts_with_ngrams = []
    for idx in range(len(processed_texts)):
        trigram_tokens = trigram[bigram[processed_texts[idx]]]
        processed_texts_with_ngrams.append(trigram_tokens)
    
    # Create dictionary and corpus
    dictionary = gensim.corpora.Dictionary(processed_texts_with_ngrams)
    dictionary.filter_extremes(no_below=5, no_above=0.5)
    corpus = [dictionary.doc2bow(text) for text in processed_texts_with_ngrams]

    # Train LDA model
    lda_model = gensim.models.LdaMulticore(
        corpus=corpus,
        id2word=dictionary,
        num_topics=num_topics,
        random_state=100,
        chunksize=100,
        passes=passes,
        alpha='asymmetric',
        eta='auto'
    )

    return lda_model, corpus, dictionary, processed_texts_with_ngrams

# Function to print ngrams
def print_ngrams(processed_texts_with_ngrams):
    # Print the bigram and trigram processed texts (5 examples)
    print("\n==== Corpus Examples with Bigrams/Trigrams ====\n")
    for i, text in enumerate(processed_texts_with_ngrams[:5]):
        print(f"Example {i + 1}: {' '.join(text)}")

# Function to compute coherence score
def compute_coherence_score(lda_model, processed_texts_with_ngrams, dictionary):
    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts_with_ngrams, dictionary=dictionary, coherence='c_v')
    coherence_score = coherence_model_lda.get_coherence()
    return coherence_score

# Apply LDA and print the ngrams
processed_texts = non_rst_cleaned['processed_text'].apply(lambda x: x.split()).tolist()  # Assuming tokenize_text is already defined
lda_model, corpus, dictionary, processed_texts_with_ngrams = apply_lda(processed_texts, num_topics=10)

# Print unigrams, bigrams, and trigrams used in LDA
print_ngrams(processed_texts_with_ngrams)

# Compute and print the coherence score
coherence_score = compute_coherence_score(lda_model, processed_texts_with_ngrams, dictionary)
print(f"\nCoherence Score for the LDA Model: {coherence_score:.4f}")
