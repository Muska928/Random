import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import torch
from transformers import BitsAndBytesConfig

# Load Mistral model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"

tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
)

model.config.use_cache = False  # Silence the warnings
model.config.pretraining_tp = 1
model.gradient_checkpointing_enable()

# Initialize the text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Load data from Salesforce analytics
df_salesforce = pd.read_excel('/mnt/data/Salesforce_Deals_Text_Analytics.xlsx')

# Set the chunk size and batch size
chunk_size = 1000  # Number of rows per chunk to process
batch_size = 10    # Number of prompts to process in a batch

# Define the prompt template
prompt_template = """
Analyze the following text and explain why the deal was won. After providing the explanation, categorize the deal into one of the following groups:
1. Strong Client Relationship
2. Effective Pricing
3. Operational Excellence
4. Product and Service Delivery
5. Innovative Solutions

If none of these categories fit, provide a new category that better describes the reason for winning the deal.

Text: {input_text}

Response format:
Explanation: [Provide explanation]
Category: [Choose one of the groups or suggest a new one]
"""

# Function to extract explanation and category from the model response
def extract_explanation_category(text):
    explanation = "Explanation not found"
    category = "Category not found"

    # Look for "Explanation:" and "Category:" markers
    explanation_marker = "Explanation:"
    category_marker = "Category:"

    explanation_start = text.find(explanation_marker)
    category_start = text.find(category_marker)

    if explanation_start != -1:
        if category_start != -1:
            explanation = text[explanation_start + len(explanation_marker):category_start].strip()
        else:
            explanation = text[explanation_start + len(explanation_marker):].strip()

    if category_start != -1:
        category = text[category_start + len(category_marker):].strip()

    return explanation, category

# Function to process each chunk
def process_chunk(df_chunk):
    results = []
    
    for i in tqdm(range(0, len(df_chunk), batch_size), desc="Processing"):
        batch_texts = df_chunk['combined_text'].iloc[i:i+batch_size].tolist()

        # Combine the text into the prompt
        prompts = [prompt_template.format(input_text=text) for text in batch_texts]
        
        # Process batches asynchronously
        batch_responses = generation_pipeline(prompts, max_new_tokens=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
        
        # Extract generated text from batch_responses
        for response in batch_responses:
            if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
                generated_text = response[0]['generated_text']
            elif 'generated_text' in response:
                generated_text = response['generated_text']
            else:
                generated_text = "No valid response"
            results.append(generated_text)
    
    # Combine the results into a single column
    df_chunk['final_response'] = results

    # Extract the explanation and category into separate columns
    df_chunk[['explanation', 'category']] = df_chunk['final_response'].apply(lambda x: pd.Series(extract_explanation_category(x)))

    return df_chunk

# Process the data in chunks and save the output incrementally
output_file = '/mnt/data/Salesforce_Deals_Text_Analytics_Output.csv'

# Process in chunks to manage memory usage
for chunk_start in range(0, len(df_salesforce), chunk_size):
    chunk_end = min(chunk_start + chunk_size, len(df_salesforce))
    df_chunk = df_salesforce.iloc[chunk_start:chunk_end]
    
    # Process the chunk
    processed_chunk = process_chunk(df_chunk)
    
    # Save the processed chunk to the output CSV
    if chunk_start == 0:
        processed_chunk.to_csv(output_file, index=False, mode='w')  # Write header only once
    else:
        processed_chunk.to_csv(output_file, index=False, mode='a', header=False)

print(f"Processing complete. Output saved to {output_file}.")
