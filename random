

# Load Data
df = pd.read_csv('closed_won_final.csv')  # Adjust the path to your data
df = df.head(10)  # Limiting to 1000 rows for demonstration
total_rows = len(df)

# Function to chunk text based on token length
def chunk_text(text, max_length=128):
    tokens = tokenizer.encode(text, truncation=False)
    # Split tokens into chunks of size max_length
    return [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]

# Updated classify_texts function with debugging
def classify_texts(df_batch):
    assigned_categories = []
    sub_categories = []
    specific_processes = []
    account_opening_flags = []

    # Updated prompt with detailed category descriptions
    prompt_template = """
    You are an AI tasked with classifying financial and business process texts. For each text, first understand the context and then classify it into one of the following main categories, subcategories, or assign it to "Other" if none of the categories fit.

    **Main Categories:**

    1. **Product Capability** (e.g., This category includes strong product offerings such as ACH Direct Send, BAI reporting, treasury services, and other banking products that provide operational or transactional capabilities to clients.)
       - Subcategories: ACH Direct Send, BAI Reporting, Treasury Services, Other Product Capability, Cash Management Solutions, Reporting Enhancements

    2. **Client-Specific Solutions** (e.g., Tailored solutions to meet the unique needs of a client. These could include setting up new accounts, managing existing accounts, or making modifications to suit a clientâ€™s specific operational needs.)
       - Subcategories: New Account (e.g., "New Account International," Corporate DDA Opening, Multi-currency Account Setup), Account Modification (Account Maintenance, Currency Account Modification, Limits Adjustments), Incremental Account (Subsidiary Account Addition, Multiple Account Setup), Account Transfer (Cross-border Account Transfer, Entity Transfer, Currency Switch)

    3. **Client Services** (e.g., Services related to client support, such as onboarding new clients, handling client mandates, or facilitating their day-to-day banking and financial activities.)
       - Subcategories: Client Onboarding (Smooth Onboarding, Implementation Services, Initial Setup), Client Mandate (Corporate Client Mandate, Legal Entity Directive, Mandate Changes), Client Deposit (Liquidity Management, Deposit Solutions, Multi-currency Deposits), Client Request, Client Interest

    4. **Relationship and Wallet Share** (e.g., Expanding relationships with existing clients by offering additional services and increasing the amount of business they do with the bank.)
       - Subcategories: Relationship Expansion, Additional Services, Increased Wallet Share

    5. **Geographical Expansion** (e.g., Opening accounts in new regions or for international entities. This might involve setting up new accounts or expanding existing services to other countries or regions.)
       - Subcategories: New Region Account (Regional Expansion, Cross-border Account Setup, Global Accounts), International Expansion (Foreign Entity Creation, Global Business Setup, Currency Expansion)

    6. **Competitor Comparison** (e.g., Highlighting advantages over competitors, particularly in pricing or service offerings. This category often includes comparative analyses of products and services offered by competitors.)
       - Subcategories: Pricing Advantages (Lower Pricing, Cost Reduction, Service Pricing), Service Comparison (Feature Comparison, Competitor Differentiation, Service Offering Comparison), Competitor Analysis

    7. **Client Onboarding and Implementation** (e.g., Efficient onboarding and smooth transitions for new clients or services. This can also include activities related to the integration of new services or delivery effectiveness.)
       - Subcategories: Onboarding Efficiency, Smooth Transitions (Transition Assistance, Operational Shift, Business Continuity), Delivery Effectiveness

    8. **Market Disruption** (e.g., This category includes events where clients switch due to market disruptions or instability. It may include shifts driven by economic instability, market competition, or crisis-induced changes.)
       - Subcategories: Competitor Switch (Competitive Advantage, Service Improvement, Competitor Takeover), Market Disruption (Economic Instability, Crisis Response, Financial Disruption), Stability Offering (Market Stability, Risk Mitigation, Crisis Management)

    9. **Other Processes** (e.g., Processes not related to the above categories, such as regulatory compliance, system upgrades, or technical services like H2H connectivity.)
       - Subcategories: System Development (Core Banking Systems, Payment Infrastructure), Vault Services (Cash Vault, Safekeeping, Vault Operations), H2H Connectivity (Host-to-Host Connectivity, Direct Banking Integration)

    10. **Other**: If the text does not match any of the above categories, classify it as "Other" and assign a relevant sub-category or "Other" if no sub-category fits.

    For each text, provide a high-level category, a relevant sub-category with specifics, and a 2-3 word process description based on the context.

    Text: "{input_text}"

    ### Response Format:
    1. Main Category: [Product Capability / Client-Specific Solutions / Client Services / Relationship and Wallet Share / Geographical Expansion / Competitor Comparison / Client Onboarding and Implementation / Market Disruption / Other Processes / Other]
    2. Sub-Category: [Assigned Sub-Category with details (if applicable) or "Other"]
    3. Specific Process: [2-3 word description]
    """

    for idx, row in df_batch.iterrows():
        input_text = row["combined_text"]
        print(f"Processing row {idx+1}/{len(df_batch)}: {input_text[:100]}...")  # Debug: Show first 100 characters of the text

        # **Chunk the input text**
        text_chunks = chunk_text(input_text)  # Use input_text, not the prompt
        print(f"Text split into {len(text_chunks)} chunk(s).")  # Debug: Number of chunks
        
        # Variables to collect results from chunks
        combined_category = []
        combined_sub_category = []
        combined_process = []

        for chunk_idx, chunk in enumerate(text_chunks):
            # Convert chunk back to text
            chunk_text_decoded = tokenizer.decode(chunk)
            print(f"Processing chunk {chunk_idx+1}/{len(text_chunks)}: {chunk_text_decoded[:100]}...")  # Debug: Show first 100 characters of the chunk
            
            # Create prompt for each chunk
            prompt = prompt_template.format(input_text=chunk_text_decoded)

            # Tokenization and model inference for each chunk
            input_tokens = tokenizer(prompt, return_tensors="pt", truncation=True, padding=True, max_length=512).to(model.device)
            output = model.generate(
                input_tokens['input_ids'], 
                max_new_tokens=200, 
                pad_token_id=tokenizer.eos_token_id, 
                temperature=0.7  # Adjusting the temperature
            )

            # Decode and extract results
            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
            print(f"Generated text for chunk {chunk_idx+1}: {generated_text[:200]}...")  # Debug: Show first 200 characters of generated text

            # Extract classification results from each chunk
            category, sub_category, process = extract_classification(generated_text)

            # Collect results from each chunk
            combined_category.append(category)
            combined_sub_category.append(sub_category)
            combined_process.append(process)

        # **Aggregate chunk results**
        # For simplicity, you can take the most frequent category and process across chunks.
        final_category = max(set(combined_category), key=combined_category.count)
        final_sub_category = max(set(combined_sub_category), key=combined_sub_category.count)
        final_process = " ".join(combined_process)  # Combine processes from chunks
        print(f"Final category: {final_category}, sub-category: {final_sub_category}, process: {final_process}")  # Debug: Final output for the row

        # Save the classification results for each row
        assigned_categories.append(final_category)
        sub_categories.append(final_sub_category)
        specific_processes.append(final_process)

        # Set flag for account opening
        if final_category == "Account Management" and "New Account" in final_sub_category:
            account_opening_flags.append("Yes")
        else:
            account_opening_flags.append("No")

    df_batch['assigned_category'] = assigned_categories
    df_batch['sub_category'] = sub_categories
    df_batch['specific_process'] = specific_processes
    df_batch['is_related_to_account_opening'] = account_opening_flags

    return df_batch

# Function to extract categories, sub-categories, and specific processes
def extract_classification(text):
    # Initialize default values
    high_level_category = "Not available"
    sub_category = "Not available"
    specific_process = "Not available"

    # Log full generated text for debugging
    print(f"Generated text:\n{text}\n")  # Debug: Show full generated text

    # Normalize text to handle extra spaces or inconsistencies
    text = text.replace("**", "").strip()  # Remove any Markdown formatting (**bold**)

    # Split the generated text by newlines
    lines = text.split("\n")
    
    # Iterate over each line to extract the relevant fields
    for line in lines:
        line = line.strip()  # Remove leading/trailing whitespace
        
        # Handle potential cases where the text might not follow the exact format
        if "Main Category:" in line:
            high_level_category = line.split("Main Category:")[1].strip() if "Main Category:" in line else high_level_category
        elif "Sub-Category:" in line:
            sub_category = line.split("Sub-Category:")[1].strip() if "Sub-Category:" in line else sub_category
        elif "Specific Process:" in line:
            specific_process = line.split("Specific Process:")[1].strip() if "Specific Process:" in line else specific_process
    
    # Log the extracted categories for debugging
    print(f"Extracted Category: {high_level_category}, Sub-Category: {sub_category}, Specific Process: {specific_process}")  # Debug: Print extracted categories
    
    return high_level_category, sub_category, specific_process

# Process data in batches
def process_batches(df, batch_size):
    all_results = pd.DataFrame()

    start_time = time.time()

    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)

        df_batch = df.iloc[start:end].copy()

        # Run classification task for the batch
        df_batch = classify_texts(df_batch)

        # Concatenate results into the full dataframe
        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Measure total time taken
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Time taken to process {len(df)} records: {elapsed_time:.2f} seconds")

    # Save final combined results to a CSV file
    all_results.to_csv('final_classification_output.csv', index=False)
    print("Final results saved to final_classification_output.csv.")

# Running the batch process with batch size of 100
process_batches(df, batch_size=1)

# Display the first few rows of the final output
df_final = pd.read_csv('final_classification_output.csv')
print("First few rows of the final saved output:")
print(df_final.head())
