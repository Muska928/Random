import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm

# Load data
df = pd.read_excel('Data/closed_won_final.csv')  # Ensure this path is correct
df = df.head(10)  # Limiting to only 10 rows for demonstration
total_rows = len(df)

# Load model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Model loading
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    trust_remote_code=True,
    device_map="auto"
)

# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Dictionary to store assignments for reuse and track repetition
assignment_memory = {}

def classify_texts(df_batch):
    assigned_categories = []
    specific_processes = []
    account_opening_flags = []
    repetition_labels = []
    confidence_scores = []
    justifications = []

    # Updated prompt template for classification and location-specific context
    updated_prompt_template = """
    You are an AI tasked with reading a text related to financial and business processes. Your tasks are:
    1. Determine if the case is related to **Account Opening**. If yes, keep the assigned category as **Account Opening** and include any specific location mentioned (e.g., "Account Opening in Dubai"). If the location is not provided, assign 'Unknown Location.'
    2. If no, assign a suitable category based on your understanding of the text, reflecting the context of the case, with any relevant location (e.g., "Personnel Change in London"). If no location is mentioned, assign 'Unknown Location.'
    3. Describe the specific process in 2-3 words that is happening in the text. If the process is unclear, assign 'Not available.'
    4. If this case is similar to a previously seen case, mention it explicitly and state the name of the previously assigned process (e.g., "Repetitive case - matches previously seen process: Account Opening in Sydney").
    5. If the text is unclear or ambiguous, use the category 'Unclear' and the process 'Unknown Process' rather than leaving gaps.
    6. Ensure that each output category and process is separated by the symbol `|`.
    7. Include a confidence score (0-100%) indicating how certain you are of the assigned category.

    ### Response Format:
    1. Category: [Assigned Category | Location (if applicable)]
    2. Specific Process: [2-3 word process description]
    3. Confidence: [Confidence level (0-100%)]
    4. Repetition: [Yes/No, and if Yes, mention the process name]
    5. Justification: [Short justification for the assignment]

    Text: "{input_text}"
    """

    batch_texts = df_batch["combined_text"].tolist()

    for text in batch_texts:
        # Check if the text has been previously classified
        if text in assignment_memory:
            assigned_category, specific_process, confidence, justification = assignment_memory[text]
            assigned_categories.append(assigned_category)
            specific_processes.append(specific_process)
            confidence_scores.append(confidence)
            justifications.append(justification)
            account_opening_flags.append("Yes" if "Account Opening" in assigned_category else "No")
            repetition_labels.append(f"Repetitive case - matches previously seen process: {assigned_category}")
        else:
            # Create prompt and generate response
            prompt = updated_prompt_template.format(input_text=text)
            response = generation_pipeline(prompt, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
            
            # Extract the generated text
            generated_text = response[0]['generated_text'] if response else "No valid response"
            
            # Extract the category, specific process, confidence, repetition, and justification
            category, process, confidence, repetition, justification = extract_category_process(generated_text)
            
            assigned_categories.append(category)
            specific_processes.append(process)
            confidence_scores.append(confidence)
            repetition_labels.append(repetition)
            justifications.append(justification)
            
            # Store the result for future reuse
            assignment_memory[text] = (category, process, confidence, justification)
            
            # Set the "Account Opening" flag
            account_opening_flags.append("Yes" if "Account Opening" in category else "No")
    
    # Add the classification results, repetition label, confidence scores, justifications, and flags to the DataFrame
    df_batch['assigned_category'] = assigned_categories
    df_batch['specific_process'] = specific_processes
    df_batch['confidence_score'] = confidence_scores
    df_batch['justification'] = justifications
    df_batch['is_related_to_account_opening'] = account_opening_flags
    df_batch['repetition_label'] = repetition_labels
    
    return df_batch

# Extract the category, process, confidence, and justification from the generated text
def extract_category_process(text):
    # Split the text into lines
    lines = text.split("\n")
    category = "Not available"
    process = "Not available"
    confidence = "Not available"
    repetition = "Unique"
    justification = "Not available"

    # Loop through the lines to find the category, process, confidence, repetition, and justification
    for line in lines:
        line = line.strip()
        if line.startswith("1. Category:"):
            # Extract the category after "1. Category:"
            category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("2. Specific Process:"):
            # Extract the specific process after "2. Specific Process:"
            process = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("3. Confidence:"):
            # Extract the confidence score after "3. Confidence:"
            confidence = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("4. Repetition:"):
            # Extract the repetition information
            repetition = line.split(": ", 1)[1].strip() if ": " in line else "Unique"
        elif line.startswith("5. Justification:"):
            # Extract the justification after "5. Justification:"
            justification = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
    
    return category, process, confidence, repetition, justification

# Main function to process batches
def process_batches(df, batch_size):
    all_results = pd.DataFrame()
    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()
        
        # Run classification task
        df_batch = classify_texts(df_batch)
        
        # Append the classified results to the full dataframe
        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Save final combined results to new file after all batches are processed
    all_results.to_csv('final_classification_output_with_confidence_and_justification.csv', index=False)
    print("Final results saved to final_classification_output_with_confidence_and_justification.csv.")

# Run the process with batch size
process_batches(df, batch_size=5)

# Check the final DataFrame content
df_final = pd.read_csv('final_classification_output_with_confidence_and_justification.csv')
print(df_final.head())
