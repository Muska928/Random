import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, KBinsDiscretizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

# 1. Load Excel file
df = pd.read_excel("your_excel_file.xlsx")  # Replace with actual file name

# 2. EDA Summary
print("\nðŸ“Œ Column Names:")
print(df.columns.tolist())
print(f"\nðŸ“Š Dataset Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns")
print("\nðŸ§¼ Null Value Count per Column:")
print(df.isnull().sum())

# 3. Drop all rows with any nulls
df = df.dropna()
print(f"\nâœ… After dropping nulls: {df.shape[0]} rows remain")

# 4. Define features and target
binary_categorical_features = [
    "browser_access_flag", "jpm_lockbox_image_file_flag", "non_jpm_lockbox_image_file_flag",
    "self_scanning_lockbox_image_file_flag", "pdf_image_file_to_835_flag", "patient_payment_flag",
    "paper_eob_conversion_to_835_flag", "835_outbound_transmission_commercial_era_uploading_flag",
    "epic_cash_management_file_flag", "835_outbound_transmission_commercial_flag",
    "835_outbound_transmission_patientpay_flag", "outbound_hcl_image_transmission_flag",
    "reconciliation_manager_flag", "reconciliation_manager_enterprise_flag", "corr_index_flag",
    "835_packet_split_flag", "fispan_flag"
]

multi_categorical_features = ["pli_type", "prod_tx", "grade"]
categorical_features = binary_categorical_features + multi_categorical_features
target = "pli_active_cycle_time"

X = df[categorical_features]
y = df[target]

# 5. Preprocessing pipeline
preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
])

pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", LinearRegression())
])

# 6. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Fit model
pipeline.fit(X_train, y_train)

# 8. Predict
y_pred = pipeline.predict(X_test)

# 9. Evaluation
print("\nðŸ“ˆ Model Evaluation:")
print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
print(f"RÂ² Score: {r2_score(y_test, y_pred):.2f}")

# 10. Predict for full dataset
df["predicted_cycle_time"] = pipeline.predict(X)

# 11. Binning complexity scores
binning = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')
df["complexity_score"] = binning.fit_transform(df[["predicted_cycle_time"]]).astype(int) + 1

# 12. Plot: Actual vs Predicted
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Cycle Time")
plt.ylabel("Predicted Cycle Time")
plt.title("Actual vs Predicted (Test Set)")
plt.grid(True)
plt.tight_layout()
plt.show()

# 13. Plot: Complexity Score Distribution
plt.figure(figsize=(6, 4))
sns.countplot(x="complexity_score", data=df)
plt.title("Complexity Score Distribution")
plt.xlabel("Complexity (1 = Low, 5 = High)")
plt.tight_layout()
plt.show()

# 14. Save Output
df.to_excel("pli_with_complexity_scores.xlsx", index=False)
print("âœ… Excel saved as 'pli_with_complexity_scores.xlsx'")

