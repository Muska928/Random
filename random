import pandas as pd
import spacy
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import re

# Load Spacy model (without custom stopwords)
nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])

# Function to preprocess text
def preprocess(document):
    document = document.lower()
    document = re.sub(r'[^a-zA-Z\s]', '', document)
    document = re.sub(r'\s+', ' ', document).strip()
    doc = nlp(document)
    words = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and len(token.lemma_) > 2]
    return words

# Read data from Salesforce analytics (replace with actual file path)
df_salesforce = pd.read_excel('Data/exclude_won_rst.xlsx')

# Concatenate text columns into a single string variable
df_salesforce['combined_text'] = df_salesforce[['record_comment_text', 
                                                'executive_summary_text', 
                                                'win_loss_reason_text', 
                                                'win_loss_comments_text']].apply(lambda x: ' '.join(x.dropna()), axis=1)

# Preprocess the combined text
df_salesforce['processed_text'] = df_salesforce['combined_text'].apply(preprocess)

# Token count for each row
df_salesforce['token_count'] = df_salesforce['processed_text'].apply(len)

# Function to analyze n-gram frequencies and plot them
def analyze_ngrams(df_subset, title):
    all_tokens = [token for sublist in df_subset['processed_text'] for token in sublist]
    total_token_count = len(all_tokens)
    print(f"Total Token Count ({title}): {total_token_count}")

    # Get the frequency of n-grams
    ngram_freq = Counter(all_tokens)

    # Select top 20 most frequent n-grams
    top_20_ngrams = ngram_freq.most_common(20)

    # Create DataFrame for visualization
    ngram_df = pd.DataFrame(top_20_ngrams, columns=['ngram', 'frequency'])

    # Plot the top 20 n-grams
    plt.figure(figsize=(12, 8))
    sns.barplot(x='ngram', y='frequency', data=ngram_df, palette='coolwarm')
    plt.xticks(rotation=45, ha='right', fontsize=12)
    plt.yticks(fontsize=12)
    plt.title(f'Top 20 Most Frequent N-grams ({title})', fontsize=16, weight='bold')
    plt.xlabel('N-gram', fontsize=14, weight='bold')
    plt.ylabel('Frequency', fontsize=14, weight='bold')

    # Add data labels for each bar
    for index, value in enumerate(ngram_df['frequency']):
        plt.text(index, value + 500, str(value), ha='center', fontsize=12)

    plt.tight_layout()
    plt.show()

# 1) Analysis for RST Data
rst_data = df_salesforce[df_salesforce['account_eci'] == 'RST']
print(f"Total RST Data Count: {len(rst_data)}")
analyze_ngrams(rst_data, 'RST Data')

# 2) Analysis for Non-RST Data
non_rst_data = df_salesforce[df_salesforce['account_eci'] != 'RST']
print(f"Total Non-RST Data Count: {len(non_rst_data)}")
analyze_ngrams(non_rst_data, 'Non-RST Data')

# 3) Analysis for token length <= 3
token_len_le_3_data = df_salesforce[df_salesforce['token_count'] <= 3]
print(f"Total Data with Token Length <= 3: {len(token_len_le_3_data)}")
analyze_ngrams(token_len_le_3_data, 'Token Length <= 3')

# 4) Analysis for token length >= 4
token_len_ge_4_data = df_salesforce[df_salesforce['token_count'] >= 4]
print(f"Total Data with Token Length >= 4: {len(token_len_ge_4_data)}")
analyze_ngrams(token_len_ge_4_data, 'Token Length >= 4')
