import pyLDAvis
import pyLDAvis.gensim_models as gensimvis

# Generate the pyLDAvis visualization
vis_data = gensimvis.prepare(optimal_model, corpus, dictionary)

# Filter out only the rows where 'Category' is actually a topic (e.g., 'Topic1', 'Topic2', ..., 'Topic14')
topic_categories = [f"Topic{i+1}" for i in range(optimal_model.num_topics)]  # Generates 'Topic1', 'Topic2', ..., 'Topic14'
topic_proportions = vis_data.topic_info.loc[vis_data.topic_info['Category'].isin(topic_categories), ['Category', 'Freq']]

# Normalize the frequencies to get percentages
total_freq = topic_proportions['Freq'].sum()
topic_proportions['Freq'] = (topic_proportions['Freq'] / total_freq) * 100  # Convert to percentage

# Remove duplicates if any exist
topic_proportions = topic_proportions.drop_duplicates(subset=['Category'])

# Sort topics by their proportions
sorted_topics = topic_proportions.sort_values(by='Freq', ascending=False)

# Print the topic proportions and corresponding top words (from PyLDAvis) in a clean format
print("Normalized Topic Proportions and Top Words (Matching PyLDAvis):")

# Extracting the top words for each topic from PyLDAvis data
for idx, row in sorted_topics.iterrows():
    topic_id = int(row['Category'].replace("Topic", ""))  # Extract topic number
    # Extract the top 10 words for this topic from the PyLDAvis term data
    top_words_df = vis_data.token_table[vis_data.token_table['Topic'] == topic_id]
    top_words = top_words_df.sort_values(by='Freq', ascending=False)['Term'].head(10).tolist()
    top_words_str = ', '.join(top_words)  # Convert to a string
    print(f"{row['Category']} ({row['Freq']:.2f}%): {top_words_str}")

# Visualize the pyLDAvis output (in a Jupyter Notebook, for example)
pyLDAvis.display(vis_data)
