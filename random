import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch
from tqdm import tqdm

# Load data
df = pd.read_csv('Data/closed_won_final.csv')
df_sample = df.head(100).copy()  # Make an explicit copy to avoid SettingWithCopyWarning

# Define model path and tokenizer for LDA-based tasks
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Configuration for model optimization
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

# Load model with quantization settings
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True
)

# Disable cache and enable gradient checkpointing
model.config.use_cache = False
model.gradient_checkpointing_enable()

# Define the text generation pipeline for classification and topic alignment
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Function to classify text based on Category and Explanation
def classify_texts():
    results = []
    batch_size = 10

    # Define the prompt template for classification
    updated_prompt_template = """
    You are a highly intelligent AI model trained to analyze and classify text based on its content.
    Your task is to:
    1. Summarize the main topic or focus of the following text in 2-3 words.
    2. Provide a brief explanation for why this category fits the text.

    ### Instructions:
    1. Read the provided text carefully.
    2. Identify the main topic or focus of the text.
    3. Summarize the topic in 2-3 words (e.g., "Client Relationship", "Account Setup").
    4. Provide a short explanation of why you have chosen this category.

    Now, classify the following text:

    Text: "{input_text}"

    Please provide your response in the following format:
    1. Category: [A concise 2-3 word summary of the main topic]
    2. Explanation: [Briefly explain why this classification fits the given text]
    """

    # Process in batches
    for i in tqdm(range(0, len(df_sample), batch_size), desc="Processing Classification"):
        batch_texts = df_sample["combined_text"].iloc[i:i+batch_size].tolist()

        # Create prompts
        prompts = [updated_prompt_template.format(input_text=text) for text in batch_texts]

        # Generate output
        batch_responses = generation_pipeline(prompts, max_new_tokens=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

        # Process batch responses
        for response in batch_responses:
            if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
                generated_text = response[0]["generated_text"]
            elif 'generated_text' in response:
                generated_text = response['generated_text']
            else:
                generated_text = "No valid response"
            results.append(generated_text)

    # Combine results into the DataFrame
    df_sample['final_response_classify'] = results

    # Extract the "Category" and "Explanation"
    def extract_information(text):
        lines = text.split("\n")
        category = "Not available"
        explanation = "Not available"

        for line in lines:
            if line.startswith("1. Category:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    category = parts[1].strip()
            elif line.startswith("2. Explanation:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    explanation = parts[1].strip()

        return category, explanation

    # Apply the extraction and create new columns for classification
    df_sample[['category', 'explanation']] = df_sample['final_response_classify'].apply(lambda x: pd.Series(extract_information(x)))

# Function for Topic Alignment With LDA
def topic_alignment_lda():
    results = []
    batch_size = 10

    # Define the updated prompt template to check topic alignment with text context
    updated_prompt_template = """
    You are an AI tasked with verifying if the assigned topic name matches the context of the content provided.
    Assess whether the topic assigned is relevant and appropriate for the text.
    Given the following text, identify if the assigned topic name aligns with the content and provide a classification:
    Assigned Topic Name: {topic_name}
    Text: {input_text}

    Provide your response in the following format:
    Topic Alignment: (Yes/No)
    Explanation: [Brief explanation of why the topic does or does not match the content]
    """

    # Generate the output in batches
    for i in tqdm(range(0, len(df_sample), batch_size), desc="Processing Topic Alignment"):
        batch_texts = df_sample["combined_text"].iloc[i:i+batch_size].tolist()
        assigned_topics = df_sample["main_topic_name"].iloc[i:i+batch_size].tolist()

        # Create prompts
        prompts = [updated_prompt_template.format(topic_name=topic, input_text=text) for topic, text in zip(assigned_topics, batch_texts)]

        # Generate batch responses
        batch_responses = generation_pipeline(prompts, max_new_tokens=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

        # Extract generated text from batch_responses
        for response in batch_responses:
            if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
                generated_text = response[0]["generated_text"]
            elif 'generated_text' in response:
                generated_text = response['generated_text']
            else:
                generated_text = "No valid response"
            results.append(generated_text)

    # Combine the results into a single column
    df_sample['final_response_topic_alignment'] = results

    # Extract the topic alignment and explanation into separate columns
    def extract_information(text):
        lines = text.split("\n")
        topic_alignment = "Not available"
        explanation = "Not available"

        for line in lines:
            if line.startswith("Topic Alignment:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    topic_alignment = parts[1]
            elif line.startswith("Explanation:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    explanation = parts[1]

        return topic_alignment, explanation

    # Apply the extraction and create new columns for topic alignment
    df_sample[['topic_alignment', 'topic_explanation']] = df_sample['final_response_topic_alignment'].apply(lambda x: pd.Series(extract_information(x)))

# Run both functions
classify_texts()  # For Category and Explanation extraction
topic_alignment_lda()  # For Topic Alignment extraction with LDA

# Save the results to a CSV file with both outputs
df_sample.to_csv('new_Deals_Topic_Alignment_Output.csv', index=False)

# Display results for verification
print(df_sample[['category', 'explanation', 'topic_alignment', 'topic_explanation']])
