import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm

# Load data
df = pd.read_excel('Data/closed_won_final.csv')  # Ensure this path is correct
df = df.head(10)  # Limiting to only 10 rows for demonstration
total_rows = len(df)

# Load model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Model loading
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    trust_remote_code=True,
    device_map="auto"
)

# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Function to classify text dynamically, assign a generic category, and set the "Account Opening" flag
def classify_texts(df_batch):
    assigned_categories = []
    specific_processes = []
    account_opening_flags = []

    # Define the prompt template for classification and specific process extraction
    updated_prompt_template = """
    You are an AI model tasked with reading a text related to financial processes and categorizing it into one of the following broad categories:
    - Account Opening
    - Account Closure
    - Account Configuration
    - Account Transfer
    - Other Processes
    
    After assigning the broad category, you must also describe the specific process (in 2-3 words) that is happening in the text. 
    
    Example:
    Text: "The client wants to open a new account."
    Broad Category: Account Opening
    Specific Process: New Account Request

    Now, read the following text and provide the broad category and the specific process.

    Text: "{input_text}"

    ### Response Format:
    1. Broad Category: [Assigned Category]
    2. Specific Process: [2-3 word process description]
    """
    
    batch_texts = df_batch["combined_text"].tolist()
    
    # Create prompts and generate responses
    prompts = [updated_prompt_template.format(input_text=text) for text in batch_texts]
    batch_responses = generation_pipeline(prompts, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    
    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]['generated_text']
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        
        # Extract the category and specific process
        category, process = extract_category_process(generated_text)
        assigned_categories.append(category)
        specific_processes.append(process)
        
        # Set the "Account Opening" flag
        if "Account Opening" in category:
            account_opening_flags.append("Yes")
        else:
            account_opening_flags.append("No")
    
    df_batch['assigned_category'] = assigned_categories
    df_batch['specific_process'] = specific_processes
    df_batch['is_related_to_account_opening'] = account_opening_flags
    
    return df_batch

# Extract the broad category and specific process from the generated text
def extract_category_process(text):
    lines = text.split("\n")
    category = "Not available"
    process = "Not available"

    for line in lines:
        if line.strip().startswith("Broad Category:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                category = parts[1].strip()
        elif line.strip().startswith("Specific Process:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                process = parts[1].strip()
    
    return category, process

# Main function to process batches
def process_batches(df, batch_size):
    all_results = pd.DataFrame()
    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()
        
        # Run classification task
        df_batch = classify_texts(df_batch)
        
        # Append the classified results to the full dataframe
        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Save final combined results to new file after all batches are processed
    all_results.to_csv('final_classification_output_with_process.csv', index=False)
    print("Final results saved to final_classification_output_with_process.csv.")

# Run the process with batch size
process_batches(df, batch_size=5)

# Check the final DataFrame content
df_final = pd.read_csv('final_classification_output_with_process.csv')
print(df_final.head())
