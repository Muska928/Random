# Import necessary libraries
import pandas as pd
import spacy
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
from spacy.lang.en.stop_words import STOP_WORDS
import gensim
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis
from gensim.models import CoherenceModel
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Load Spacy model and data
nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])
df_salesforce = pd.read_excel('/mnt/data/C04CEE5D-B307-4900-9397-558F2770CC69.xlsx')

# Function to apply LDA after bigram and trigram creation
def apply_lda(processed_texts, num_topics=10, passes=10):
    # Create bigram and trigram models
    bigram = gensim.models.Phrases(processed_texts, min_count=10)
    trigram = gensim.models.Phrases(bigram[processed_texts], min_count=10)

    # Add bigrams and trigrams to texts
    processed_texts_with_ngrams = []
    for idx in range(len(processed_texts)):
        trigram_tokens = trigram[bigram[processed_texts[idx]]]
        processed_texts_with_ngrams.append(trigram_tokens)
    
    # Create dictionary and corpus
    dictionary = gensim.corpora.Dictionary(processed_texts_with_ngrams)
    dictionary.filter_extremes(no_below=5, no_above=0.5)
    corpus = [dictionary.doc2bow(text) for text in processed_texts_with_ngrams]

    # Train LDA model
    lda_model = gensim.models.LdaMulticore(
        corpus=corpus,
        id2word=dictionary,
        num_topics=num_topics,
        random_state=100,
        chunksize=100,
        passes=passes,
        alpha='asymmetric',
        eta='auto'
    )

    return lda_model, corpus, dictionary, processed_texts_with_ngrams

# Function to print ngrams
def print_ngrams(processed_texts_with_ngrams):
    # Print the bigram and trigram processed texts (5 examples)
    print("\n==== Corpus Examples with Bigrams/Trigrams ====\n")
    for i, text in enumerate(processed_texts_with_ngrams[:5]):
        print(f"Example {i + 1}: {' '.join(text)}")

# Function to compute coherence score
def compute_coherence_score(lda_model, processed_texts_with_ngrams, dictionary):
    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts_with_ngrams, dictionary=dictionary, coherence='c_v')
    coherence_score = coherence_model_lda.get_coherence()
    return coherence_score

# Function to visualize topic frequency using a bar graph
def plot_topic_frequency(lda_model, corpus):
    topic_counts = [sum([count for id, count in topic]) for topic in corpus]
    topics = lda_model.print_topics(num_words=5)
    
    # Create a DataFrame for frequency and topics
    topic_data = pd.DataFrame({
        'Topic': [f'Topic {i}' for i in range(len(topics))],
        'Topic Name': [topic[1] for topic in topics],
        'Frequency': topic_counts
    })

    # Print Topic Frequency Summary
    print("\nLDA Topic Frequency Summary:\n")
    print(topic_data)

    # Plot the bar graph
    sns.barplot(x='Topic Name', y='Frequency', data=topic_data)
    plt.title("LDA Topic Frequency Summary")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

# Apply LDA and print the ngrams
processed_texts = non_rst_cleaned['processed_text'].apply(lambda x: x.split()).tolist()  # Assuming tokenize_text is already defined
lda_model, corpus, dictionary, processed_texts_with_ngrams = apply_lda(processed_texts, num_topics=10)

# Print unigrams, bigrams, and trigrams used in LDA
print_ngrams(processed_texts_with_ngrams)

# Compute and print the coherence score
coherence_score = compute_coherence_score(lda_model, processed_texts_with_ngrams, dictionary)
print(f"\nCoherence Score for the LDA Model: {coherence_score:.4f}")

# Visualize the topic frequency with a bar chart
plot_topic_frequency(lda_model, corpus)
