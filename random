import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch
from transformers import BitsAndBytesConfig

# Function to truncate text to a maximum of 4096 tokens
def truncate_to_4096_tokens(text):
    if isinstance(text, str):  # Ensure that text is a string
        tokens = text.split()
        if len(tokens) > 4096:
            tokens = tokens[:4096]
        return ' '.join(tokens)
    else:
        return ''  # Return an empty string or handle the NaN case appropriately

# Load Mistral model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)
tokenizer.pad_token = tokenizer.eos_token

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",  # Automatically map to available devices
    trust_remote_code=True,
)

model.config.use_cache = False
model.config.pretraining_tp = 1
model.gradient_checkpointing_enable()

generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)

# Define the prompt template
prompt_template = """
Analyze the following text and explain why the deal was won. After providing the explanation, categorize the deal into one of the following groups:
1. Strong Client Relationship
2. Effective Pricing
3. Operational Excellence
4. Product and Service Delivery
5. Innovative Solutions

If none of these categories fit, provide a new category that better describes the reason for winning the deal.

Text: {input_text}

Response format:
Explanation: [Provide explanation]
Category: [Choose one of the groups or suggest a new one]
"""

# Load the dataset
df_salesforce = pd.read_excel('Data/LLM_Won_Analysis.xlsx')

# Apply truncation to the 'combined_text' column
df_salesforce['combined_text'] = df_salesforce['combined_text'].apply(truncate_to_4096_tokens)

# Prepare the prompts
prompts = [prompt_template.format(input_text=text) for text in df_salesforce['combined_text']]

# Generate responses
responses = generation_pipeline(prompts, max_new_tokens=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

# Extract generated text into a list
results = []
for response in responses:
    if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
        generated_text = response[0]['generated_text']
    elif 'generated_text' in response:
        generated_text = response['generated_text']
    else:
        generated_text = "No valid response"
    results.append(generated_text)

# Split results into explanation and category
df_salesforce['final_response'] = results
df_salesforce['explanation'] = df_salesforce['final_response'].apply(lambda x: x.split("Explanation: ")[1].split("Category: ")[0].strip())
df_salesforce['category'] = df_salesforce['final_response'].apply(lambda x: x.split("Category: ")[1].strip())

# Save the processed DataFrame to a CSV file
df_salesforce.to_csv('LLM_Won_Analysis_Output.csv', index=False)

print("Processing complete. Output saved to LLM_Won_Analysis_Output.csv.")
