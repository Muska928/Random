import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import os

# Load data
df = pd.read_csv('Data/closed_won_final.csv')  # Make sure this path is correct
total_rows = len(df)

# Load model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Model loading
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    trust_remote_code=True,
    device_map="auto"
)

# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Function to save batch results to disk
def save_results(df_sample, start, end, filename='intermediate_results.csv'):
    if not os.path.exists(filename):
        df_sample.to_csv(filename, index=False, mode='w')
    else:
        df_sample.to_csv(filename, index=False, mode='a', header=False)
    print(f"Batch {start}-{end} saved.")

# Function to resume from the last processed batch
def get_last_saved_batch(filename='intermediate_results.csv'):
    if os.path.exists(filename):
        df_saved = pd.read_csv(filename)
        return len(df_saved)
    return 0

# Function to classify text based on Category and Explanation
def classify_texts(df_batch):
    results = []

    updated_prompt_template = """
    You are a highly intelligent AI model trained to analyze and classify text based on its content.
    Your task is to:
    1. Summarize the main topic or focus of the following text in 2-3 words.
    2. Provide a brief explanation for why this category fits the text.

    Now, classify the following text:

    Text: "{input_text}"

    Please provide your response in the following format:
    1. Category: [A concise 2-3 word summary of the main topic]
    2. Explanation: [Briefly explain why this classification fits the given text]
    """

    batch_texts = df_batch["combined_text"].tolist()

    # Create prompts and generate responses
    prompts = [updated_prompt_template.format(input_text=text) for text in batch_texts]
    batch_responses = generation_pipeline(prompts, max_new_tokens=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]["generated_text"]
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        results.append(generated_text)

    df_batch['final_response_classify'] = results

    # Extract the "Category" and "Explanation"
    def extract_information_classify(text):
        lines = text.split("\n")
        category = "Not available"
        explanation = "Not available"

        for line in lines:
            if line.strip().startswith("1. Category:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    category = parts[1].strip()
            elif line.strip().startswith("2. Explanation:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    explanation = parts[1].strip()

        return category, explanation

    df_batch[['category', 'explanation']] = df_batch['final_response_classify'].apply(lambda x: pd.Series(extract_information_classify(x)))

# Function for Topic Alignment With LDA
def topic_alignment_lda(df_batch):
    results = []

    updated_prompt_template = """
    You are an AI tasked with verifying if the assigned topic name matches the context of the content provided.
    Given the following text, identify if the assigned topic name aligns with the content and provide a classification:
    Assigned Topic Name: {topic_name}
    Text: {input_text}

    Provide your response in the following format:
    Topic Alignment: (Yes/No)
    Explanation: [Brief explanation of why the topic does or does not match the content]
    """

    batch_texts = df_batch["combined_text"].tolist()
    assigned_topics = df_batch["main_topic_name"].tolist()

    prompts = [updated_prompt_template.format(topic_name=topic, input_text=text) for topic, text in zip(assigned_topics, batch_texts)]
    batch_responses = generation_pipeline(prompts, max_new_tokens=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]["generated_text"]
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        results.append(generated_text)

    df_batch['final_response_topic_alignment'] = results

    # Extract topic alignment and explanation
    def extract_information_alignment(text):
        lines = text.split("\n")
        topic_alignment = "Not available"
        explanation = "Not available"

        for line in lines:
            if line.strip().startswith("Topic Alignment:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    topic_alignment = parts[1].strip()
            elif line.strip().startswith("Explanation:"):
                parts = line.split(": ", 1)
                if len(parts) > 1:
                    explanation = parts[1].strip()

        return topic_alignment, explanation

    df_batch[['topic_alignment', 'topic_explanation']] = df_batch['final_response_topic_alignment'].apply(lambda x: pd.Series(extract_information_alignment(x)))

# Main function to process batches
def process_batches(df, batch_size):
    last_processed_row = get_last_saved_batch()  # Check where to resume from
    print(f"Resuming from row {last_processed_row}...")

    for start in range(last_processed_row, total_rows, batch_size):
        end = min(start + batch_size, total_rows)

        # Get the batch to process
        df_batch = df.iloc[start:end].copy()

        # Run classification task
        classify_texts(df_batch)

        # Run topic alignment task
        topic_alignment_lda(df_batch)

        # Save intermediate results
        save_results(df_batch, start, end)

# Run the process
process_batches(df, batch_size=100)

# Save final results
df.to_csv('new_Deals_Topic_Alignment_Output.csv', index=False)

# Display results for verification
print(df[['category', 'explanation', 'topic_alignment', 'topic_explanation']].head())
