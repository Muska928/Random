

# 2. EDA Summary
print("\nðŸ“Œ Column Names:")
print(df.columns.tolist())
print(f"\nðŸ“Š Dataset Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns")
print("\nðŸ§¼ Null Value Count per Column:")
print(df.isnull().sum())

# 3. Fix: Map binary flags & check before dropping
binary_columns = [
    "browser_access_flag", "jpm_lockbox_image_file_flag", "non_jpm_lockbox_image_file_flag",
    "self_scanning_lockbox_image_file_flag", "pdf_image_file_to_835_flag", "patient_payment_flag",
    "paper_eob_conversion_to_835_flag", "835_outbound_transmission_commercial_era_uploading_flag",
    "epic_cash_management_file_flag", "835_outbound_transmission_commercial_flag",
    "835_outbound_transmission_patientpay_flag", "outbound_hcl_image_transmission_flag",
    "reconciliation_manager_flag", "reconciliation_manager_enterprise_flag", "corr_index_flag",
    "835_packet_split_flag", "fispan_flag"
]

for col in binary_columns:
    df[col] = df[col].map({'Yes': 1, 'No': 0})
    df[col] = df[col].fillna(0)

for col in binary_columns:
    print(f"{col} unique values after mapping:", df[col].unique())

# 4. Drop rows with nulls only in relevant columns
print("\nðŸ“Š Shape before dropping nulls:", df.shape)
df = df.dropna(subset=["pli_active_cycle_time", "pli_type", "prod_tx", "grade"])
print("âœ… Shape after safe drop:", df.shape)

# 5. Define features and target
features = binary_columns + ["pli_type", "prod_tx", "grade"]
target = "pli_active_cycle_time"

X = df[features]
y = df[target]

categorical_features = ["pli_type", "prod_tx", "grade"]
numeric_features = list(set(features) - set(categorical_features))

# 6. Preprocessing
preprocessor = ColumnTransformer([
    ("num", MinMaxScaler(), numeric_features),
    ("cat", OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
])

# 7. Pipeline
pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", LinearRegression())
])

# 8. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 9. Fit
pipeline.fit(X_train, y_train)

# 10. Predict on test set
y_pred = pipeline.predict(X_test)

# 11. Evaluation
print("\nðŸ“ˆ Model Evaluation:")
print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
print(f"RÂ² Score: {r2_score(y_test, y_pred):.2f}")

# 12. Predict on full data
df["predicted_cycle_time"] = pipeline.predict(X)

# 13. Complexity scoring
binning = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')
df["complexity_score"] = binning.fit_transform(df[["predicted_cycle_time"]]).astype(int) + 1

# 14. Feature Importance
regressor = pipeline.named_steps['regressor']
feature_names = (
    numeric_features +
    list(pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))
)
weights_df = pd.DataFrame({
    "Feature": feature_names,
    "Weight": regressor.coef_
}).sort_values(by="Weight", ascending=False)

print("\nðŸ“Œ Feature Weights:")
print(weights_df)

# 15. Charts
plt.figure(figsize=(10, 5))
sns.barplot(data=weights_df.head(10), x="Weight", y="Feature", palette="viridis")
plt.title("Top 10 Feature Drivers of Complexity")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Cycle Time")
plt.ylabel("Predicted Cycle Time")
plt.title("Actual vs Predicted (Test Set)")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(6, 4))
sns.countplot(x="complexity_score", data=df)
plt.title("Complexity Score Distribution")
plt.xlabel("Complexity (1 = Low, 5 = High)")
plt.tight_layout()
plt.show()

# 16. Save outputs
df.to_excel("pli_with_complexity_scores.xlsx", index=False)
weights_df.to_excel("feature_weights.xlsx", index=False)
print("âœ… Files saved: 'pli_with_complexity_scores.xlsx' & 'feature_weights.xlsx'")
