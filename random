import pandas as pd
import re
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
from tqdm import tqdm

# Load data from Salesforce analytics
df_salesforce = pd.read_excel('/mnt/data/Salesforce_Deals_Text_Analytics.xlsx')

# Concatenate text columns into a single string variable
df_salesforce['combined_text'] = df_salesforce[
    ['record_comment_text', 'description_text', 'executive_summary_text', 'win_loss_reason_text', 'win_loss_comments_text']
].apply(lambda x: ' '.join(x.dropna()), axis=1)

# Preprocess the text
def preprocess_text(text):
    text = text.lower()  # Convert text to lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and numbers
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra whitespace
    return text

# Apply preprocessing
df_salesforce['combined_text'] = df_salesforce['combined_text'].apply(preprocess_text)

# Sample 1000 records
df_sample = df_salesforce.sample(n=1000, random_state=42)  # random_state for reproducibility

# Load Mistral model and tokenizer from the specified folder with device_map='auto'
model_path = "./mistral"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path, device_map='auto')

# Sentiment analysis pipeline with return_all_scores=True
sentiment_pipeline = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, return_all_scores=True)

# Define middle office keywords
middle_office_keywords = ['service', 'onboarding', 'processing', 'operations', 'compliance']

# Function to check if text is related to middle office
def is_middle_office_related(text, keywords):
    return 'yes' if any(keyword in text for keyword in keywords) else 'no'

# Apply the sentiment analysis using one-shot prompting
print("Applying sentiment analysis...")
sentiments = []
probabilities = []
middle_office_flags = []

for text in tqdm(df_sample['combined_text']):
    response = sentiment_pipeline(text)

    # Ensure the response has scores and extract the sentiment with highest score
    if response:
        # Extract the highest score sentiment
        sentiment = max(response[0], key=lambda x: x['score'])
        sentiment_label = sentiment['label']
        probability = sentiment['score']

        sentiments.append(sentiment_label)
        probabilities.append(probability)
    else:
        # Handle cases where the sentiment extraction fails
        sentiments.append(None)
        probabilities.append(None)
    
    # Check if the text is related to middle office
    middle_office_flag = is_middle_office_related(text, middle_office_keywords)
    middle_office_flags.append(middle_office_flag)

df_sample['sentiment'] = sentiments
df_sample['probability'] = probabilities
df_sample['middle_office_related'] = middle_office_flags

# Save the output to a CSV file
output_file_path = '/mnt/data/Salesforce_Deals_Sentiment_Analysis_Sample_Output.csv'
df_sample.to_csv(output_file_path, index=False)

# Print a sample of the output in tabular form
print(df_sample[['combined_text', 'sentiment', 'probability', 'middle_office_related']].head().to_markdown())
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
from tqdm import tqdm

# Load data from Salesforce analytics
df_salesforce = pd.read_excel('/mnt/data/Salesforce_Deals_Text_Analytics.xlsx')

# Concatenate text columns into a single string variable
df_salesforce['combined_text'] = df_salesforce[
    ['record_comment_text', 'description_text', 'executive_summary_text', 'win_loss_reason_text', 'win_loss_comments_text']
].apply(lambda x: ' '.join(x.dropna()), axis=1)

# Preprocess the text
def preprocess_text(text):
    text = text.lower()  # Convert text to lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and numbers
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra whitespace
    return text

# Apply preprocessing
df_salesforce['combined_text'] = df_salesforce['combined_text'].apply(preprocess_text)

# Sample 1000 records
df_sample = df_salesforce.sample(n=1000, random_state=42)  # random_state for reproducibility

# Load Mistral model and tokenizer from the specified folder with device_map='auto'
model_path = "./mistral"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path, device_map='auto')

# Sentiment analysis pipeline with return_all_scores=True
sentiment_pipeline = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, return_all_scores=True)

# Apply the sentiment analysis using one-shot prompting
print("Applying sentiment analysis...")
sentiments = []
probabilities = []

for text in tqdm(df_sample['combined_text']):
    response = sentiment_pipeline(text)

    # Ensure the response has scores and extract the sentiment with highest score
    if response:
        # Extract the highest score sentiment
        sentiment = max(response[0], key=lambda x: x['score'])
        sentiment_label = sentiment['label']
        probability = sentiment['score']

        sentiments.append(sentiment_label)
        probabilities.append(probability)
    else:
        # Handle cases where the sentiment extraction fails
        sentiments.append(None)
        probabilities.append(None)

df_sample['sentiment'] = sentiments
df_sample['probability'] = probabilities

# Save the output to a CSV file
output_file_path = '/mnt/data/Salesforce_Deals_Sentiment_Analysis_Sample_Output.csv'
df_sample.to_csv(output_file_path, index=False)

# Print a sample of the output in tabular form
print(df_sample[['combined_text', 'sentiment', 'probability']].head().to_markdown())






# Apply the sentiment and trigger analysis using one-shot prompting
print("Applying one-shot prompting...")
sentiments = []
triggers = []
probabilities = []
lobs = []

for text in tqdm(df_sample['combined_text']):
    prompt = one_shot_template.format(text=text)
    response = sentiment_pipeline(prompt)

    # Extract generated text from response
    generated_text = response[0]['generated_text'] if 'generated_text' in response[0] else ""

    sentiment_label = re.search(r'Sentiment:\s*(POSITIVE|NEGATIVE|CANCELLED)', generated_text)
    trigger_text = re.search(r'Trigger:\s*(.*)', generated_text)
    lob_text = re.search(r'LOB:\s*(.*)', generated_text)

    # Ensure that sentiment_label, trigger_text, and lob_text are found
    if sentiment_label and trigger_text and lob_text:
        sentiment_label = sentiment_label.group(1)
        trigger_text = trigger_text.group(1)
        lob_text = lob_text.group(1)

        # Extract probabilities
        scores = {label['label']: label['score'] for label in response[0]}
        probability = scores[sentiment_label]

        sentiments.append(sentiment_label)
        triggers.append(trigger_text)
        probabilities.append(probability)
        lobs.append(lob_text)
    else:
        # Handle cases where sentiment, trigger, or LOB extraction fails
        sentiments.append(None)
        triggers.append(None)
        probabilities.append(None)
        lobs.append(None)

df_sample['sentiment'] = sentiments
df_sample['trigger'] = triggers
df_sample['probability'] = probabilities
df_sample['lob'] = lobs

# Save the output to a CSV file
output_file_path = '/mnt/data/Salesforce_Deals_Sentiment_Analysis_Sample_Output.csv'
df_sample.to_csv(output_file_path, index=False)

# Print a sample of the output in tabular form
print(df_sample[['combined_text', 'sentiment', 'trigger', 'probability', 'lob']].head().to_markdown())
