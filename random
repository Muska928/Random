import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, KBinsDiscretizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

# 1. Load your Excel file
df = pd.read_excel("your_excel_file.xlsx")  # âœ… Update the filename here

# 2. Drop rows with missing target values
df = df.dropna(subset=["pli_active_cycle_time"])

# 3. Define features and target
features = [
    "browser_access_flag", "jpm_lockbox_image_file_flag", "non_jpm_lockbox_image_file_flag",
    "self_scanning_lockbox_image_file_flag", "pdf_image_file_to_835_flag", "patient_payment_flag",
    "paper_eob_conversion_to_835_flag", "835_outbound_transmission_commercial_era_uploading_flag",
    "epic_cash_management_file_flag", "835_outbound_transmission_commercial_flag",
    "835_outbound_transmission_patientpay_flag", "outbound_hcl_image_transmission_flag",
    "reconciliation_manager_flag", "reconciliation_manager_enterprise_flag", "corr_index_flag",
    "835_packet_split_flag", "pli_type", "prod_tx", "fispan_flag", "grade"
]
target = "pli_active_cycle_time"

X = df[features]
y = df[target]

categorical_features = ["pli_type", "prod_tx", "grade"]
numeric_features = list(set(features) - set(categorical_features))

# 4. Preprocessing
preprocessor = ColumnTransformer([
    ("num", MinMaxScaler(), numeric_features),
    ("cat", OneHotEncoder(drop='first'), categorical_features)
])

# 5. Create pipeline
pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", LinearRegression())
])

# 6. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Fit the model
pipeline.fit(X_train, y_train)

# 8. Predict on test set
y_pred = pipeline.predict(X_test)

# 9. Evaluate
print("\nðŸ“Š Model Evaluation:")
print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
print(f"RÂ² Score: {r2_score(y_test, y_pred):.2f}")

# 10. Predict on full data for scoring/export
df["predicted_cycle_time"] = pipeline.predict(X)

binning = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')
df["complexity_score"] = binning.fit_transform(df[["predicted_cycle_time"]]).astype(int) + 1

# 11. Plot - Actual vs Predicted
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Cycle Time")
plt.ylabel("Predicted Cycle Time")
plt.title("Actual vs Predicted (Test Set)")
plt.grid(True)
plt.tight_layout()
plt.show()

# 12. Plot - Complexity Score Distribution
plt.figure(figsize=(6, 4))
sns.countplot(x="complexity_score", data=df)
plt.title("Complexity Score Distribution")
plt.xlabel("Complexity (1 = Low, 5 = High)")
plt.tight_layout()
plt.show()

# 13. Save output
df.to_excel("pli_with_complexity_scores.xlsx", index=False)
print("âœ… Excel with predictions saved as 'pli_with_complexity_scores.xlsx'")

