import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import time  # For measuring time taken

# Load data
df = pd.read_excel('Data/closed_won_final.csv')  # Ensure this path is correct
df = df.head(100)  # Limiting to 100 rows for demonstration
total_rows = len(df)

# Load model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Model loading
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    trust_remote_code=True,
    device_map="auto"
)

# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Define the updated prompt template
dynamic_prompt_template = """
You are an AI tasked with classifying financial and business process texts. For each text, first **understand the context** and then classify it into one of the following main categories, subcategories, or assign it to "Other" if none of the categories fit. If none of the subcategories fit, assign the subcategory to "Other" under the relevant main category.

**Main Categories:**
1. **Product Capability** (e.g., ACH Direct Send, BAI Reporting, Treasury Services)
    - Subcategories: Wires, Online Access (e.g., JPM Access or Chase Connect), Lockbox, Checks
    - Example: Deals won due to strong product offerings such as ACH Direct Send, BAI Reporting, treasury services, Wires, and online access through JPM Access or Chase Connect. Clients found products tailored to their needs and easy to integrate with their business processes.
    
2. **Client-Specific Solutions** (e.g., Customization for new account setups, Specific Currency Accounts)
    - Subcategories: New Account Setup, Specific Client Currency Accounts, Customization
    - Example: Winning deals due to responsiveness to client-specific needs.

3. **Market Disruption** (e.g., Stability in times of market volatility)
    - Subcategories: Market Volatility, Stability Solutions
    - Example: Clients switching from competitors during disruptions.

4. **Relationship and Wallet Share** (e.g., Expanding existing client relationships, increasing wallet share)
    - Subcategories: Expanding Services, Cross-Sell, Client Retention
    - Example: Strengthening relationships to win additional services from clients.

5. **Geographical Expansion** (e.g., Opening new accounts in international regions)
    - Subcategories: New International Accounts, Regional Expansion
    - Example: Deals involving opening accounts in new regions or entities.

6. **Competitor Comparison** (e.g., Highlighting advantages over competitors in offerings or pricing)
    - Subcategories: Pricing Advantages, Product Superiority, Service Offering Superiority
    - Example: Winning deals by emphasizing advantages over competitors.

7. **Client Onboarding and Implementation** (e.g., Smooth transition and service implementation)
    - Subcategories: Onboarding Efficiency, Smooth Service Implementation
    - Example: Deals won due to efficient onboarding and smooth service delivery.

8. **Other**: If the text does not match any of the above categories, classify it as "Other" and assign a relevant sub-category or "Other" if no sub-category fits.

For each text, provide a high-level category, a relevant sub-category with specifics, and a 2-3 word process description based on the context.

Text: "{input_text}"

### Response Format:
1. Main Category: [Product Capability / Client-Specific Solutions / Market Disruption / Relationship and Wallet Share / Geographical Expansion / Competitor Comparison / Client Onboarding and Implementation / Other]
2. Sub-Category: [Assigned Sub-Category with details (if applicable) or "Other"]
3. Specific Process: [2-3 word description]
"""

# Define the text classification function
def classify_texts(df_batch, max_input_tokens=512, max_output_tokens=100):
    assigned_categories = []
    sub_categories = []
    specific_processes = []
    account_opening_flags = []

    batch_texts = df_batch["combined_text"].tolist()

    for text in batch_texts:
        # Tokenize and truncate input text
        input_tokens = tokenizer(text, truncation=True, max_length=max_input_tokens, return_tensors='pt')

        # Create prompt and generate response
        prompt = dynamic_prompt_template.format(input_text=text)
        response = generation_pipeline(prompt, max_new_tokens=max_output_tokens, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
        
        # Extract the generated text
        generated_text = response[0]['generated_text'] if response else "No valid response"
        
        # Extract high-level category, sub-category, and specific process
        high_level_category, sub_category, process = extract_classification(generated_text)
        
        # Handle cases where no category is found
        if high_level_category == "Not available":
            high_level_category = "Other"
        if sub_category == "Not available":
            sub_category = "Other"
        
        # Append results
        assigned_categories.append(high_level_category)
        sub_categories.append(sub_category)
        specific_processes.append(process)
        
        # Set the "Account Opening" flag based on category
        account_opening_flags.append("Yes" if high_level_category == "Account Management" and sub_category == "New Account" else "No")
    
    # Add the classification results and account opening flags to the DataFrame
    df_batch['assigned_category'] = assigned_categories
    df_batch['sub_category'] = sub_categories
    df_batch['specific_process'] = specific_processes
    df_batch['is_related_to_account_opening'] = account_opening_flags
    
    return df_batch

# Extract the high-level category, sub-category, and specific process from the generated text
def extract_classification(text):
    # Split the text into lines
    lines = text.split("\n")
    high_level_category = "Not available"
    sub_category = "Not available"
    specific_process = "Not available"

    # Loop through the lines to find the high-level category, sub-category, and specific process
    for line in lines:
        line = line.strip()
        if line.startswith("1. Main Category:"):
            high_level_category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("2. Sub-Category:"):
            sub_category = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
        elif line.startswith("3. Specific Process:"):
            specific_process = line.split(": ", 1)[1].strip() if ": " in line else "Not available"
    
    return high_level_category, sub_category, specific_process

# Main function to process batches
def process_batches(df, batch_size):
    all_results = pd.DataFrame()

    # Measure the start time
    start_time = time.time()

    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()
        
        # Run classification task
        df_batch = classify_texts(df_batch)
        
        # Append the classified results to the full dataframe
        all_results = pd.concat([all_results, df_batch], ignore_index=True)

    # Measure the end time
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Time taken to process {len(df)} records: {elapsed_time:.2f} seconds")

    # Save final combined results to new file after all batches are processed
    all_results.to_csv('final_classification_output_with_account_flag.csv', index=False)
    print("Final results saved to final_classification_output_with_account_flag.csv.")

# Run the process with batch size
process_batches(df, batch_size=10)

# Check the final DataFrame content
df_final = pd.read_csv('final_classification_output_with_account_flag.csv')
print(df_final.head())
