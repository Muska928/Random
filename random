import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import os

# Load data
df = pd.read_excel('Data/closed_won_final.csv')  # Make sure this path is correct
df = df.head(500)  # Using a subset for testing
total_rows = len(df)

# Load model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

# Model Loading
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    trust_remote_code=True,
    device_map="auto"
)

# Set up text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Function to save batch results to disk
def save_results(df_sample, filename='3_intermediate_results.csv'):
    if not os.path.exists(filename):
        df_sample.to_csv(filename, index=False, mode='w')
    else:
        df_sample.to_csv(filename, index=False, mode='a', header=False)
    print(f"Batch saved to {filename}.")

# Function to classify text based on Category and Explanation with added logic for "account opening"
def classify_texts_with_check(df_batch, previous_assignments):
    results = []

    # Define the prompt template for classification
    updated_prompt_template = """
    You are a highly intelligent AI model trained to analyze and classify text based on its content.
    If the text is related to 'account opening', keep the same classification.
    Otherwise, provide a more suitable classification.

    Your task is to:
    1. Summarize the main topic or focus of the following text in 2-3 words.
    2. Provide a brief explanation for why this category fits the text.
    
    ### Instructions:
    1. Read the provided text carefully.
    2. If the topic is related to 'account opening,' return the same classification. 
    3. If not, classify the text with a more appropriate topic.
    4. Provide a short explanation of why you have chosen this category.
    
    Now, classify the following text:

    Text: "{input_text}"
    
    Please provide your response in the following format:
    1. Category: [A concise 2-3 word summary of the main topic]
    2. Explanation: [Briefly explain why this classification fits the given text]
    """

    batch_texts = df_batch["combined_text"].tolist()

    for text in batch_texts:
        # Check if the text is in previous assignments
        if text in previous_assignments:
            # Reuse previous assignment if found
            generated_text = previous_assignments[text]
        else:
            # Create the prompt and ask for classification if not related to 'account opening'
            prompt = updated_prompt_template.format(input_text=text)
            response = generation_pipeline(prompt, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

            if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
                generated_text = response[0]['generated_text']
            elif 'generated_text' in response:
                generated_text = response['generated_text']
            else:
                generated_text = "No valid response"
            
            # Store the generated text for future use
            previous_assignments[text] = generated_text
        
        results.append(generated_text)

    df_batch['final_response_classify'] = results

# Extract the "Category" and "Explanation"
def extract_information_classify(text):
    lines = text.split("\n")
    category = "Not available"
    explanation = "Not available"

    for line in lines:
        if line.strip().startswith("1. Category:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                category = parts[1].strip()
        elif line.strip().startswith("2. Explanation:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                explanation = parts[1].strip()
    
    return category, explanation

# Function for Topic Alignment With LDA
def topic_alignment_lda(df_batch):
    results = []

    # Define the updated prompt template to check topic alignment with text context
    updated_prompt_template = """
    You are an AI tasked with verifying if the assigned topic name matches the context of the content provided.
    Assess whether the topic assigned is relevant and appropriate for the text.
    Given the following text, identify if the assigned topic name aligns with the content:
    
    Assigned Topic Name: {topic_name}
    Text: {input_text}
    
    Provide your response in the following format:
    Topic Alignment: (Yes/No)
    Explanation: [Brief explanation of why the topic does or does not match the content]
    """
    
    batch_texts = df_batch["combined_text"].tolist()
    assigned_topics = df_batch["main_topic_name"].tolist()
    
    prompts = [updated_prompt_template.format(topic_name=topic, input_text=text) for topic, text in zip(assigned_topics, batch_texts)]
    batch_responses = generation_pipeline(prompts, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    
    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]['generated_text']
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        results.append(generated_text)
    
    df_batch['final_response_topic_alignment'] = results

# Extract topic alignment and explanation
def extract_information_alignment(text):
    lines = text.split("\n")
    topic_alignment = "Not available"
    explanation = "Not available"

    for line in lines:
        if line.strip().startswith("Topic Alignment:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                topic_alignment = parts[1].strip()
        elif line.strip().startswith("Explanation:"):
            parts = line.split(": ", 1)
            if len(parts) > 1:
                explanation = parts[1].strip()
    
    return topic_alignment, explanation

# Main function to process batches
def process_batches(df, batch_size):
    previous_assignments = {}  # Dictionary to store previous topic assignments
    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()

        # Run the modified classification task with topic check
        classify_texts_with_check(df_batch, previous_assignments)
        
        # Run topic alignment task
        topic_alignment_lda(df_batch)

        # Save intermediate results after processing
        save_results(df_batch, filename='3_intermediate_results.csv')

    # Save final combined results to new file after all batches are processed
    df_combined = pd.read_csv('3_intermediate_results.csv')
    df_combined.to_csv('new_Deals_Topic_Alignment_Output.csv', index=False)
    print("Final results saved to new_Deals_Topic_Alignment_Output.csv.")

# Run the process with batch size
process_batches(df, batch_size=100)

# Display results for verification
df_final = pd.read_csv('new_Deals_Topic_Alignment_Output.csv')
print(df_final[['category', 'explanation', 'topic_alignment', 'topic_explanation']].head())
