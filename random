import pandas as pd
import spacy
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import re
import gensim
from datetime import datetime

# Load Spacy model (without custom stopwords)
nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])
nlp.max_length = 2000000  # Increase SpaCy's max_length to handle larger texts

# Import custom stopwords
df_stopwords = pd.read_csv('list_stopwords.csv')
stopword_list = df_stopwords['Words'].to_list()

# Adding stopwords to spacy module
for word in stopword_list:
    nlp.Defaults.stop_words.add(word)
    nlp.vocab[word].is_stop = True

# Contractions and abbreviations mapping
contractions_dict = {
    "ain't": "are not","'s":" is","aren't": "are not","can't": "cannot","can't've": "cannot have",
    "'cause": "because","could've": "could have","couldn't": "could not","couldn't've": "could not have",
    "didn't": "did not","doesn't": "does not","don't": "do not","hadn't": "had not","hadn't've": "had not have",
    "hasn't": "has not","haven't": "have not","he'd": "he would","he'd've": "he would have","he'll": "he will",
    "he'll've": "he will have","how'd": "how did","how'd'y": "how do you","how'll": "how will","I'd": "I would",
    "I'd've": "I would have","I'll": "I will","I'll've": "I will have","I'm": "I am","I've": "I have","isn't": "is not",
    "it'd": "it would","it'd've": "it would have","it'll": "it will","it'll've": "it will have","let's": "let us",
    "ma'am": "madam","mayn't": "may not","might've": "might have","mightn't": "might not","mightn't've": "might not have",
    "must've": "must have","mustn't": "must not","mustn't've": "must not have","needn't": "need not","needn't've": "need not have",
    "o'clock": "of the clock","oughtn't": "ought not","oughtn't've": "ought not have","shan't": "shall not",
    "sha'n't": "shall not","shan't've": "shall not have","she'd": "she would","she'd've": "she would have","she'll": "she will",
    "she'll've": "she will have","should've": "should have","shouldn't": "should not","shouldn't've": "should not have",
    "so've": "so have","that'd": "that would","that'd've": "that would have","there'd": "there would","there'd've": "there would have",
    "they'd": "they would","they'd've": "they would have","they'll": "they will","they'll've": "they will have","they're": "they are",
    "they've": "they have","to've": "to have","wasn't": "was not","we'd": "we would","we'd've": "we would have","we'll": "we will",
    "we'll've": "we will have","we're": "we are","we've": "we have","weren't": "were not","what'll": "what will","what'll've": "what will have",
    "what're": "what are","what've": "what have","when've": "when have","where'd": "where did","where've": "where have",
    "who'll": "who will","who'll've": "who will have","who've": "who have","why've": "why have","will've": "will have",
    "won't": "will not","won't've": "will not have","would've": "would have","wouldn't": "would not","wouldn't've": "would not have",
    "y'all": "you all","y'all'd": "you all would","y'all'd've": "you all would have","y'all're": "you all are",
    "y'all've": "you all have","you'd": "you would","you'd've": "you would have","you'll": "you will","you'll've": "you will have",
    "you're": "you are","you've": "you have"
}

# Function to expand contractions
contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))
def expand_contractions(text):
    def replace(match):
        return contractions_dict[match.group(0)]
    return contractions_re.sub(replace, text)

# Function to remove digits
def remove_digits(text):
    return re.sub(r'\d+', '', text)

# Function to remove extra punctuation/marks
def remove_extra_marks(text):
    return re.sub(r'[^\w\s]', '', text)

# Function to remove stopwords
def remove_stopwords(text):
    doc = nlp(text)
    return ' '.join([token.text for token in doc if not token.is_stop])

# Function to lemmatize
def lemmatize(text):
    doc = nlp(text)
    return ' '.join([token.lemma_ for token in doc])

# Full preprocessing pipeline
def full_preprocess(text):
    text = expand_contractions(text)  # Step 1: Expand contractions
    text = text.lower()  # Step 2: Convert to lowercase
    text = remove_digits(text)  # Step 3: Remove digits
    text = remove_extra_marks(text)  # Step 4: Remove extra marks
    text = remove_stopwords(text)  # Step 5: Remove stopwords
    text = lemmatize(text)  # Step 6: Lemmatization
    return text

# Example text
first_row_text = "ACQUIRE: Union Bank takeaway. Domestic cash management and Equipment Finance opportunity."

# Print the original text
print("Original Text:\n", first_row_text)

# Apply full preprocessing on the first row
processed_first_row = full_preprocess(first_row_text)

# Print the processed text
print("\nProcessed Text:\n", processed_first_row)
