import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import torch
from transformers import BitsAndBytesConfig

# Load Mistral model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"

tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True,
    padding_side="left",
    use_fast=True,
    add_bos_token=True,
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
)

model.config.use_cache = False  # silence the warnings
model.config.pretraining_tp = 1
model.gradient_checkpointing_enable()

# Initialize the text generation pipeline
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Load data from Salesforce analytics
df_salesforce = pd.read_excel('/mnt/data/Salesforce_Deals_Text_Analytics.xlsx')

# Set the chunk size and batch size
chunk_size = 1000  # Number of rows per chunk to process
batch_size = 10    # Number of prompts to process in a batch

# Define the prompt template
updated_prompt_template = """
You are an AI tasked with verifying if the assigned topic name matches the content of the text. Additionally, classify the content into one of the following categories: Strong Client Relationship and Market Engagement, Effective Pricing and Profitability, Operational Excellence and Process Efficiency, Product and Service Delivery, or Innovative and Tailored Solutions.

Here are the categories and their descriptions:
1. Strong Client Relationship and Market Engagement: Deals won by fostering strong client relationships and market engagement.
2. Effective Pricing and Profitability: Deals structured for profitability and competitive pricing.
3. Operational Excellence and Process Efficiency: Deals secured through reliable and efficient processes.
4. Product and Service Delivery: Deals won by meeting specific client needs with product or service offerings.
5. Innovative and Tailored Solutions: Deals won through innovative and customized solutions.

Given the following text, identify if the assigned topic name aligns with the content and categorize the deal:

Assigned Topic Name: {topic_name}
Text: {input_text}

Provide your response in the following format:
Topic Alignment: [Yes/No]
Category: [Category Name]
Explanation: [Brief explanation of why the category was chosen]
"""

# Function to extract information from the model response
def extract_information(text):
    lines = text.split("\n")
    topic_alignment = "Not available"
    category = "Not available"
    explanation = "Not available"
    
    for line in lines:
        if line.startswith("Topic Alignment:"):
            topic_alignment = line.split(": ")[1]
        elif line.startswith("Category:"):
            category = line.split(": ")[1]
        elif line.startswith("Explanation:"):
            explanation = line.split(": ")[1]
    
    return topic_alignment, category, explanation

# Function to process each chunk
def process_chunk(df_chunk):
    results = []
    
    for i in tqdm(range(0, len(df_chunk), batch_size), desc="Processing"):
        batch_texts = df_chunk['combined_text'].iloc[i:i+batch_size].tolist()
        assigned_topics = df_chunk['assigned_topic_name'].iloc[i:i+batch_size].tolist()

        # Combine the assigned topic and text into the prompt
        prompts = [updated_prompt_template.format(topic_name=topic, input_text=text) for topic, text in zip(assigned_topics, batch_texts)]
        
        # Process batches asynchronously
        batch_responses = generation_pipeline(prompts, max_new_tokens=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
        
        # Extract generated text from batch_responses
        for response in batch_responses:
            if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
                generated_text = response[0]['generated_text']
            elif 'generated_text' in response:
                generated_text = response['generated_text']
            else:
                generated_text = "No valid response"
            results.append(generated_text)
    
    # Combine the results into a single column
    df_chunk['final_response'] = results

    # Extract the topic alignment, category, and explanation into separate columns
    df_chunk[['topic_alignment', 'category', 'explanation']] = df_chunk['final_response'].apply(lambda x: pd.Series(extract_information(x)))

    return df_chunk

# Process the data in chunks and save the output incrementally
output_file = '/mnt/data/Salesforce_Deals_Text_Analytics_Output.csv'

# Process in chunks to manage memory usage
for chunk_start in range(0, len(df_salesforce), chunk_size):
    chunk_end = min(chunk_start + chunk_size, len(df_salesforce))
    df_chunk = df_salesforce.iloc[chunk_start:chunk_end]
    
    # Process the chunk
    processed_chunk = process_chunk(df_chunk)
    
    # Save the processed chunk to the output CSV
    if chunk_start == 0:
        processed_chunk.to_csv(output_file, index=False, mode='w')  # Write header only once
    else:
        processed_chunk.to_csv(output_file, index=False, mode='a', header=False)

print(f"Processing complete. Output saved to {output_file}.")
