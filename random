import pandas as pd
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from tqdm import tqdm
import torch
from transformers import BitsAndBytesConfig

# Load your dataset (assuming the dataset has 'text_column' and 'opportunity_source_name' columns)
df = pd.read_excel('/mnt/data/Text_Classification_Data.xlsx')

# Predefined categories for classification
categories = [
    "Strong Client Relationship and Market Engagement",
    "Effective Pricing and Profitability",
    "Operational Excellence and Process Efficiency",
    "Product and Service Delivery",
    "Innovative and Tailored Solutions"
]

# Define the prompt template for classification
classification_prompt_template = """
You are an AI tasked with classifying the following text into one of the following categories: 
1. Strong Client Relationship and Market Engagement
2. Effective Pricing and Profitability
3. Operational Excellence and Process Efficiency
4. Product and Service Delivery
5. Innovative and Tailored Solutions

Additionally, explain why the text belongs to the selected category.

Text: {input_text}

Based on the content of this text, which category does it belong to and why?
"""

# Load Mistral model and tokenizer
model_path = "mistral/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(
    model_path, 
    trust_remote_code=True, 
    padding_side="left", 
    use_fast=True, 
    add_bos_token=True, 
    add_eos_token=True
)

tokenizer.pad_token = tokenizer.eos_token

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
)

model.config.use_cache = False
model.gradient_checkpointing_enable()

# Pipeline for text generation
generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer)

# Process the dataset in batches
results = []
batch_size = 10

for i in tqdm(range(0, len(df), batch_size), desc="Processing"):
    batch_texts = df['text_column'].iloc[i:i+batch_size].tolist()

    # Prepare prompts for classification
    prompts = [classification_prompt_template.format(input_text=text) for text in batch_texts]
    
    # Generate the classification output from the LLM
    batch_responses = generation_pipeline(prompts, max_new_tokens=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    
    # Extract the generated classification response
    for response in batch_responses:
        if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
            generated_text = response[0]['generated_text']
        elif 'generated_text' in response:
            generated_text = response['generated_text']
        else:
            generated_text = "No valid response"
        results.append(generated_text)

# Combine the results into a single column
df['final_response'] = results

# Extract Category and Reason from the response
def extract_information(text):
    lines = text.split("\n")
    category = "Not available"
    reason = "Not available"
    
    for line in lines:
        if line.startswith("Category:"):
            category = line.split(": ")[1]
        elif line.startswith("Reason:"):
            reason = line.split(": ")[1]
    
    return category, reason

# Apply the extraction function and create new columns for Category and Reason
df[['category', 'reason_for_category']] = df['final_response'].apply(lambda x: pd.Series(extract_information(x)))

# Save the results to a CSV file with the new columns
df.to_csv('/mnt/data/Text_Classification_Results.csv', index=False)

# Display the output to verify results
print(df[['category', 'reason_for_category']])

# Generate summary statistics and conclusions
def generate_summary_report(df):
    total_deals = len(df)
    total_wins = df[df['category'].str.contains('Strong Client Relationship')].shape[0]
    total_losses = total_deals - total_wins
    
    # Count the categories and common reasons for wins/losses
    category_counts = df['category'].value_counts()
    common_reasons = df['reason_for_category'].value_counts().nlargest(3)
    
    # Generate the business report
    report = f"""
    WIN-LOSS ANALYSIS REPORT
    
    Total Deals Analyzed: {total_deals}
    Total Wins: {total_wins}
    Total Losses: {total_losses}
    
    Breakdown of Categories:
    {category_counts.to_string()}
    
    Top 3 Reasons for Wins/Losses:
    {common_reasons.to_string()}
    
    Summary:
    Our analysis of {total_deals} deals reveals that {total_wins} deals were won due to strong client relationships and market engagement. 
    However, we lost {total_losses} deals, largely due to issues related to pricing and product delivery.
    
    Recommendations:
    1. Focus on strengthening client relationships to maintain the momentum in wins.
    2. Revisit pricing strategies for highly competitive markets where we are losing deals.
    3. Enhance product customization to better meet client-specific needs, which could prevent losses due to service delivery issues.
    
    Next Steps:
    To improve our win rates in the future, we should develop strategies focused on price optimization and better product flexibility to meet the needs of diverse clients.
    """
    
    return report

# Generate the report
business_report = generate_summary_report(df)

# Save the report to a text file
with open('/mnt/data/Win_Loss_Analysis_Report.txt', 'w') as f:
    f.write(business_report)

# Display the report for quick view
print(business_report)
