# Maximum length of input tokens
max_input_length = 200

# Generate the output
results = []
for text in tqdm(df_sample['combined_text'], desc="Processing"):
    # Truncate the input text if it exceeds the maximum length
    input_tokens = tokenizer.encode(text, max_length=max_input_length, truncation=True)
    truncated_text = tokenizer.decode(input_tokens, skip_special_tokens=True)
    
    prompt = one_shot_template.format(input_text=truncated_text)
    response = generation_pipeline(prompt, max_new_tokens=50, num_return_sequences=1)[0]['generated_text']
    results.append(response)

# Split the results into separate columns
df_sample['final_response'] = results
df_sample[['LOB', 'Sentiment', 'Content Retrieved']] = df_sample['final_response'].str.extract(
    r'LOB: (.*?)\nSentiment: (.*?)\nContent Retrieved: (.*)', expand=True
)

# Save the results to an Excel file
df_sample.to_excel('/mnt/data/Salesforce_Deals_Text_Analytics_Output.xlsx', index=False)
