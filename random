# Function to classify text based on Category and Explanation with added logic for "account opening"
def classify_texts_with_check(df_batch, previous_assignments):
    results = []

    # Define the prompt template for classification
    updated_prompt_template = """
    You are a highly intelligent AI model trained to analyze and classify text based on its content.
    If the text is related to 'account opening', keep the same classification.
    Otherwise, provide a more suitable classification.

    Your task is to:
    1. Summarize the main topic or focus of the following text in 2-3 words.
    2. Provide a brief explanation for why this category fits the text.
    
    ### Instructions:
    1. Read the provided text carefully.
    2. If the topic is related to 'account opening,' return the same classification. 
    3. If not, classify the text with a more appropriate topic.
    4. Provide a short explanation of why you have chosen this category.
    
    Now, classify the following text:

    Text: "{input_text}"
    
    Please provide your response in the following format:
    1. Category: [A concise 2-3 word summary of the main topic]
    2. Explanation: [Briefly explain why this classification fits the given text]
    """

    batch_texts = df_batch["combined_text"].tolist()

    for text in batch_texts:
        # Check if the text is in previous assignments
        if text in previous_assignments:
            # Reuse previous assignment if found
            generated_text = previous_assignments[text]
        else:
            # Create the prompt and ask for classification if not related to 'account opening'
            prompt = updated_prompt_template.format(input_text=text)
            response = generation_pipeline(prompt, max_new_tokens=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)

            if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:
                generated_text = response[0]['generated_text']
            elif 'generated_text' in response:
                generated_text = response['generated_text']
            else:
                generated_text = "No valid response"
            
            # Store the generated text for future use
            previous_assignments[text] = generated_text
        
        results.append(generated_text)

    df_batch['final_response_classify'] = results

# Update the process_batches function to include previous topic assignments storage
def process_batches(df, batch_size):
    previous_assignments = {}  # Dictionary to store previous topic assignments
    for start in tqdm(range(0, total_rows, batch_size), desc="Processing Batches"):
        end = min(start + batch_size, total_rows)
        
        # Get the batch to process
        df_batch = df.iloc[start:end].copy()

        # Run the modified classification task with topic check
        classify_texts_with_check(df_batch, previous_assignments)
        
        # Run topic alignment task
        topic_alignment_lda(df_batch)

        # Save intermediate results after processing
        save_results(df_batch, filename='3_intermediate_results.csv')

    # Save final combined results to new file after all batches are processed
    df_combined = pd.read_csv('3_intermediate_results.csv')
    df_combined.to_csv('new_Deals_Topic_Alignment_Output.csv', index=False)
    print("Final results saved to new_Deals_Topic_Alignment_Output.csv.")

# Run the process with batch size
process_batches(df, batch_size=100)
