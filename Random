# Required Imports
import pandas as pd
import spacy
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
from spacy.lang.en.stop_words import STOP_WORDS
import gensim
from gensim import corpora
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis
from datetime import datetime
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Code to load data and process unigrams, bigrams, and trigrams remains the same

# Function to feed n-grams into LDA and print them
def prepare_corpus_for_lda(data):
    # Tokenizing the processed text
    tokenized_text = [text.split() for text in data]
    
    # Print the tokenized unigrams, bigrams, and trigrams (for debugging)
    print("\n--- Unigrams, Bigrams, Trigrams being fed into LDA ---\n")
    for idx, tokens in enumerate(tokenized_text[:5]):  # Limiting to first 5 records for clarity
        print(f"Record {idx + 1}: {tokens}")
    
    # Create dictionary and corpus needed for LDA
    dictionary = corpora.Dictionary(tokenized_text)
    corpus = [dictionary.doc2bow(text) for text in tokenized_text]
    
    return dictionary, corpus, tokenized_text

# Function to run LDA and display topics
def run_lda(dictionary, corpus, num_topics=5):
    # Create LDA model using Gensim
    lda_model = gensim.models.LdaModel(
        corpus=corpus,
        id2word=dictionary,
        num_topics=num_topics,
        random_state=42,
        update_every=1,
        passes=10,
        alpha='auto',
        per_word_topics=True
    )
    
    # Print the topics found by LDA
    print("\n--- LDA Topics ---\n")
    topics = lda_model.print_topics(num_words=10)
    for idx, topic in topics:
        print(f"Topic {idx + 1}: {topic}")
    
    return lda_model

# Visualize the LDA model results using pyLDAvis
def visualize_lda(lda_model, corpus, dictionary):
    lda_display = gensimvis.prepare(lda_model, corpus, dictionary, sort_topics=False)
    pyLDAvis.display(lda_display)

# Apply LDA after n-gram frequency calculation

# Preparing the corpus for LDA
dictionary, corpus, tokenized_text = prepare_corpus_for_lda(non_rst_cleaned['processed_text'])

# Running LDA model
lda_model = run_lda(dictionary, corpus, num_topics=5)

# Optional: Visualizing the LDA Model
visualize_lda(lda_model, corpus, dictionary)
